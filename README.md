# ChatGPT, GenerativeAI and LLMs Timeline 

This repository organizes a timeline of key events (products, services, papers, GitHub, blog posts and news) that occurred before and after the ChatGPT announcement. 

It's curating a variety of information in this timeline, with a particular focus on LLM and Generative AI. 

Maybe it's a scene from the hottest history, so I thought it would be important to keep those memories well, so I organized them.

## Contributing

Issues and Pull Requests are greatly appreciated. If you've never contributed to an open source project before I'm more than happy to walk you through how to create a pull request.

You can start by [opening an issue](https://github.com/hollobit/BCAC_timeline/issues/new) describing the problem that you're looking to resolve and we'll go from there.

## License

This document is licensed under the [MIT license](https://opensource.org/licenses/mit-license.php) © Jonghong Jeon

|	Date	|	Announcement	|
|:-:|:--|
| 5.9 | AvatarReX: Real-time Expressive Full-body Avatars ([arXiv](https://arxiv.org/abs/2305.04789)), ([PDF](https://arxiv.org/pdf/2305.04789.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.04789)) | 
| 5.8 | MultiModal-GPT: A Vision and Language Model for Dialogue with Humans  ([arXiv](https://arxiv.org/abs/2305.04790)), ([PDF](https://arxiv.org/pdf/2305.04790.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.04790)), ([Project page](https://github.com/open-mmlab/Multimodal-GPT)), ([Paper page](https://huggingface.co/papers/2305.04790)) |
| 5.7 | Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models ([arXiv](https://arxiv.org/abs/2305.04091)), ([PDF](https://arxiv.org/pdf/2305.04091.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.04091)), ([GitHub](https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting)) |
| 5.7 | X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages ([arXiv](https://arxiv.org/abs/2305.04160)), ([PDF](https://arxiv.org/pdf/2305.04160.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.04160)) |
| 5.7 | Multi-Space Neural Radiance Fields ([arXiv](https://arxiv.org/abs/2305.04268)), ([PDF](https://arxiv.org/pdf/2305.04268.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.04268)), ([Project page](https://zx-yin.github.io/msnerf/)), ([Dataset](https://drive.google.com/drive/folders/1gqmonTlR8LbJkljtT28S47N_o_YoExFz)) |
| 5.7 | Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting ([arXiv](https://arxiv.org/abs/2305.04388)), ([PDF](https://arxiv.org/pdf/2305.04388.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.04388)) |
| 5.7 | Yoshua Bengio - AI Scientists: Safe and Useful AI? ([Blog](https://yoshuabengio.org/2023/05/07/ai-scientists-safe-and-useful-ai/)) |
| 5.5 | privateGPT - Interact privately with your documents using the power of GPT, 100% privately, no data leaks ([GitHub](https://github.com/imartinez/privateGPT)) |
| 5.5 |  A list of open LLMs available for commercial use - ([GitHub](https://github.com/eugeneyan/open-llms)) |
| 5.5 | A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding ([arXiv](https://arxiv.org/abs/2305.03668)), ([PDF](https://arxiv.org/pdf/2305.03668.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03668)), ([GitHub](https://github.com/Luodian/Otter)), ([Papper page](https://huggingface.co/papers/2305.03668)) |
| 5.5 | Otter: A Multi-Modal Model with In-Context Instruction Tuning  ([arXiv](https://arxiv.org/abs/2305.03726)), ([PDF](https://arxiv.org/pdf/2305.03726.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03726)), ([GitHub](https://github.com/Luodian/Otter)), ([Papper page](https://huggingface.co/papers/2305.03726)) |
| 5.5 | Composite Motion Learning with Task Control ([arXiv](https://arxiv.org/abs/2305.03286)), ([PDF](https://arxiv.org/pdf/2305.03286.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03286)), ([GitHub](https://github.com/xupei0610/CompositeMotion)), ([Papper page](https://huggingface.co/papers/2305.03286)) |
| 5.5 | StarCoderBase: trained on 1T tokens in 80+ programming languages ([Huggingface](https://huggingface.co/bigcode/starcoderbase)) |
| 5.5 | Dolphin: General video interaction platform based on LLMs ([Demo](https://da2c48f45ee053ef87.gradio.live/)), ([GitHub](https://github.com/kaleido-lab/dolphin)), ([Tweet](https://twitter.com/_akhaliq)) | 
| 5.5 | MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs ([Blog](https://www.mosaicml.com/blog/mpt-7b)), Commercially usable: ([MPT-7B](https://huggingface.co/mosaicml/mpt-7b))  ([MPT-7B-Instruct](https://huggingface.co/mosaicml/mpt-7b-instruct)), ([MPT-7B-StoryWriter](https://huggingface.co/mosaicml/mpt-7b-storywriter)), For non-commerical use: ([MPT-7B-Chat](https://huggingface.co/mosaicml/mpt-7b-chat)) |
| 5.5 | StarCoder: A State-of-the-Art LLM for Code ([Blog](https://huggingface.co/blog/starcoder)), ([GitHub](https://github.com/bigcode-project/starcoder/)), ([HuggingFace](https://huggingface.co/bigcode/starcoder)), ([Tweet](https://twitter.com/BigCodeProject/status/1654174941976068119)) |
| 5.5 | OpenAlpaca, an instruction-following model based on OpenLLaMA ([GitHub](https://github.com/openlm-research/open_llama)), ([Huggingface](https://huggingface.co/openlm-research/open_llama_7b_preview_200bt)), ([Tweet](https://twitter.com/yixuan_su/status/1654234602003636226)) |
| 5.4 | Evaluating the Performance of ChatGPT in Ophthalmology: An Analysis of its Successes and Shortcomings ([Ophthalmology Science](https://www.ophthalmologyscience.org/article/S2666-9145(23)00056-8/fulltext)) | 
| 5.4 | Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction ([arXiv](https://arxiv.org/abs/2305.02466)), ([PDF](https://arxiv.org/pdf/2305.02466.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.02466)) |
| 5.4 | Governance of the AI, by the AI, and for the AI ([arXiv](https://arxiv.org/abs/2305.03719)), ([PDF](https://arxiv.org/pdf/2305.03719.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03719)), ([Papper page](https://huggingface.co/papers/2305.03719)) |
| 5.4 | Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs  ([arXiv](https://arxiv.org/abs/2305.03111)), ([PDF](https://arxiv.org/pdf/2305.03111.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03111)) |
| 5.4 | Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion ([arXiv](https://arxiv.org/abs/2305.03509)), ([PDF](https://arxiv.org/pdf/2305.03509.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03509)), ([Papper page](https://huggingface.co/papers/2305.03509)) |
| 5.4 | AttentionViz: A Global View of Transformer Attention ([arXiv](https://arxiv.org/abs/2305.03210)), ([PDF](https://arxiv.org/pdf/2305.03210.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03210)), ([Papper page](https://huggingface.co/papers/2305.03210)) |
| 5.4 | Reddit - [OpenAI lost $540M in 2022, will need $100B more to develop AGI, says Altman. My breakdown on why this matters and what it means for other AI startups](https://www.reddit.com/r/ChatGPT/comments/1383obf/openai_lost_540m_in_2022_will_need_100b_more_to/) |
| 5.4 | FACT SHEET: Biden-⁠Harris Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans’ Rights and Safety - ([White house](https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/)) |
| 5.4 | Google "We Have No Moat, And Neither Does OpenAI" - ([Blog](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)) |
| 5.4 | CNBC - [Britain launches probe into ChatGPT-style A.I. as regulators grow concerned by risks](https://www.cnbc.com/2023/05/04/chatgpt-britain-launches-competition-probe-into-ai-consumer-risks.html?utm_content=Main&utm_medium=Social&utm_source=Twitter) |
| 5.4 | Personalize Segment Anything Model with One Shot ([arXiv](https://arxiv.org/abs/2305.03048)), ([PDF](https://arxiv.org/pdf/2305.03048.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03048)), ([GitHub](https://github.com/ZrrSkywalker/Personalize-SAM)), ([Paper page](https://huggingface.co/papers/2305.03048)) |
| 5.4 | AutoML-GPT: Automatic Machine Learning with GPT ([arXiv](https://arxiv.org/abs/2305.02499)), ([PDF](https://arxiv.org/pdf/2305.02499.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.02499)), ([Paper page](https://huggingface.co/papers/2305.02499)) |
| 5.4 | NeRSemble: Multi-view Radiance Field Reconstruction of Human Heads ([arXiv](https://arxiv.org/abs/2305.03027)), ([PDF](https://arxiv.org/pdf/2305.03027.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03027), ([Project page](https://tobias-kirschstein.github.io/nersemble/)), ([Paper page](https://huggingface.co/papers/2305.03027)) |
| 5.4 | An automatically discovered chain-of-thought prompt generalizes to novel models and datasets ([arXiv](https://arxiv.org/abs/2305.02897)), ([PDF](https://arxiv.org/pdf/2305.02897.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.02897))
| 5.4 | NYT - [White House Pushes Tech C.E.O.s to Limit Risks of A.I.](https://www.nytimes.com/2023/05/04/technology/us-ai-research-regulation.html) |
| 5.4 | Microsoft Bing AI chatbot and Edge browser get massive AI upgrades. See the list. ([Blog](https://mashable.com/article/microsoft-bing-ai-chatbot-edge-browser-new-updates-features)) |
| 5.4 | Introducing Slack GPT ([Blog](https://slack.com/intl/ko-kr/blog/news/introducing-slack-gpt)) |
| 5.3 | Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings - ([Blog](https://lmsys.org/blog/2023-05-03-arena/)) |
| 5.3 | CodeGen2: Lessons for Training LLMs on Programming and Natural Languages ([arXiv](https://arxiv.org/abs/2305.02309)), ([PDF](https://arxiv.org/pdf/2305.02309.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.02309)), ([GitHub](https://github.com/salesforce/CodeGen2)) |
| 5.3 | Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes ([arXiv](https://arxiv.org/abs/2305.02301)), ([PDF](https://arxiv.org/pdf/2305.02301.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.02301)) |
| 5.3 | Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings ([arXiv](https://arxiv.org/abs/2305.02317)), ([PDF](https://arxiv.org/pdf/2305.02317.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.02317)) |
| 5.3 | AG3D: Learning to Generate 3D Avatars from 2D Image Collections ([arXiv](https://arxiv.org/abs/2305.02312)), ([PDF](https://arxiv.org/pdf/2305.02312.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.02312)), ([Project page](https://zj-dong.github.io/AG3D/)) |
| 5.3 | Shap-E: Generating Conditional 3D Implicit Functions ([arXiv](https://arxiv.org/abs/2305.02463)), ([PDF](https://arxiv.org/pdf/2305.02463.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.02463)), ([GitHub](https://github.com/openai/shap-e)), ([Paper page](https://huggingface.co/papers/2305.02463)) |
| 5.3 | 100 Practical Applications and Use Cases of Generative AI - ([PDF](https://ai.gov.ae/wp-content/uploads/2023/04/406.-Generative-AI-Guide_ver1-EN.pdf)), ([News](https://gulfnews.com/uae/uae-government-launches-guide-on-generative-ai-applications-such-as-chatgpt-1.95449467)) |  
| 5.3 | Comprehensive LLM model zoo - Ecosystem Graphs to track the foundation model ecosystem assets (datasets, models, and applications) and their relationship ([Table](https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table)), ([Graph](https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=graph)), ([GitHub](https://github.com/stanford-crfm/ecosystem-graphs)) |
| 5.3 | GPTutor: a ChatGPT-powered programming tool for code explanation ([arXiv](https://arxiv.org/abs/2305.01863)), ([PDF](https://arxiv.org/pdf/2305.01863.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.01863)) |
| 5.3 | Midjourney 5.1 Arrives - And It’s Another Leap Forward For AI Art - ([Forbes](https://www.forbes.com/sites/barrycollins/2023/05/03/midjourney-51-arrivesand-its-another-leap-forward-for-ai-art/)) |
| 5.3 | Mojo 🔥 — a new programming language for all AI developers ([Web](https://www.modular.com/mojo)), ([tweet](https://twitter.com/Modular_AI/status/1653436642248781825)), ([GitHub](https://github.com/modularml/mojo)) |
| 5.3 | #NeurIPS2023 Creative AI Track ([Blog](https://blog.neurips.cc/2023/05/02/call-for-neurips-creative-ai-track/)), ([Call for proposal](https://neurips.cc/Conferences/2023/CallForCreativeAI)) |
| 5.3 | [HeyPi](https://heypi.com/) - Personal AI |
| 5.2 | Interpretable Machine Learning for Science with PySR and SymbolicRegression.jl ([arXiv](https://arxiv.org/abs/2305.01582)), ([PDF](https://arxiv.org/pdf/2305.01582.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.01582)) |
| 5.2 | Andrew Ng - ChatGPT Prompt Engineering for Developers - ([online course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)), ([Tweet](https://twitter.com/AndrewYNg/status/1653141408386260992)) |
| 5.2 | DreamPaint: Few-Shot Inpainting of E-Commerce Items for Virtual Try-On without 3D Modeling ([arXiv](https://arxiv.org/abs/2305.01649)), ([PDF](https://arxiv.org/pdf/2305.01649.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.01649)) |
| 5.2 | Generalizing Dataset Distillation via Deep Generative Prior ([arXiv](https://arxiv.org/abs/2305.01257)), ([PDF](https://arxiv.org/pdf/2305.01257.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.01257)) |
| 5.2 | Multimodal Procedural Planning via Dual Text-Image Prompting ([arXiv](https://arxiv.org/abs/2305.01795)), ([PDF](https://arxiv.org/pdf/2305.01795.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.01795)), ([GitHub](https://github.com/YujieLu10/TIP)) |
| 5.2 | WSJ - [Google DeepMind CEO Says Some Form of AGI Possible in a Few Years](https://www.wsj.com/articles/google-deepmind-ceo-says-some-form-of-agi-possible-in-a-few-years-2705f452) |
| 5.2 | Latest NVIDIA Graphics Research Advances Generative AI’s Next Frontier ([Blog](https://blogs.nvidia.com/blog/2023/05/02/graphics-research-advances-generative-ai-next-frontier/)) |
| 5.2 | Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation ([arXiv](https://arxiv.org/abs/2305.01569)), ([PDF](https://arxiv.org/pdf/2305.01569.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.01569)), ([GitHub](https://github.com/yuvalkirstain/pickscore)) |
| 5.2 | TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis ([arXiv](https://arxiv.org/abs/2305.00976)), ([PDF](https://arxiv.org/pdf/2305.00976.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.00976)), ([Project page](https://t.co/KH4w0442YP)), ([Demo](https://huggingface.co/spaces/Mathux/TMR)) |
| 5.2 | Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation ([arXiv](https://arxiv.org/abs/2305.01210)), ([PDF](https://arxiv.org/pdf/2305.01210.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.01210)), ([GitHub](https://github.com/evalplus/evalplus)) |
| 5.2 | Unlimiformer: Long-Range Transformers with Unlimited Length Input ([arXiv](https://arxiv.org/abs/2305.01625)), ([PDF](https://arxiv.org/pdf/2305.01625.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.01625)) |
| 5.2 | Bark - Text-Prompted Generative Audio Model ([GitHub](https://github.com/suno-ai/bark)) |
| 5.2 | Jsonformer: A Bulletproof Way to Generate Structured JSON from Language Models ([GitHub](https://github.com/1rgs/jsonformer)) |
| 5.1 | scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics Using Generative AI ([bioXiv](https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1)), ([PDF](https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1.full.pdf)) |
| 5.1 | The Guardian - [AI makes non-invasive mind-reading possible by turning thoughts into text](https://www.theguardian.com/technology/2023/may/01/ai-makes-non-invasive-mind-reading-possible-by-turning-thoughts-into-text) |
| 5.1 | Learning to Reason and Memorize with Self-Notes ([arXiv](https://arxiv.org/abs/2305.00833)), ([PDF](https://arxiv.org/pdf/2305.00833.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.00833)) |
| 5.1 | Poisoning Language Models During Instruction Tuning ([arXiv](https://arxiv.org/abs/2305.00944)), ([PDF](https://arxiv.org/pdf/2305.00944.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.00944)) |
| 5.1 | What Do Self-Supervised Vision Transformers Learn? ([arXiv](https://arxiv.org/abs/2305.00729)), ([PDF](https://arxiv.org/pdf/2305.00729.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.00729)) |
| 5.1 | [NYT](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html) - ‘The Godfather of A.I.’ Leaves Google and Warns of Danger Ahead ([Archive](https://archive.is/TgPyC#selection-331.0-331.63)) |
| 4.30 | ChatGPT: Is this version good for healthcare and research? - ([ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S1871402123000401)) |
| 4.30 | Understanding Parameter-Efficient LLM Finetuning: Prompt Tuning And Prefix Tuning ([Blog](https://magazine.sebastianraschka.com/p/understanding-parameter-efficient)) |
| 4.30 | A brief history of LLaMA models ([Blog](https://agi-sphere.com/llama-models/)) |
| 4.30 | BabyBeeAGI: Task Management and Functionality Expansion on top of BabyAGI ([blog](https://yoheinakajima.com/babybeeagi-task-management-and-functionality-expansion-on-top-of-babyagi/)), ([Replit](https://replit.com/@YoheiNakajima/BabyBeeAGI?v=1)), ([GitHub](https://github.com/yoheinakajima/babyagi)), ([OG BaybyAGI](https://replit.com/@YoheiNakajima/babyagi)) |
| 4.30 | Results of G7 Digital and Tech Ministers’ Meeting in Takasaki, Gunma - ([Summary](https://g7digital-tech-2023.go.jp/en/topics/topics_20230430.html)), ([Declaration](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/ministerial_declaration_dtmm.pdf)), ([Annex1](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex1.pdf)), ([Annex2](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex2.pdf)), ([Annex3](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex3.pdf)), ([Annex4](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex4.pdf)), ([Annex5](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex5.pdf)) |
| 4.30 | PandaLM: Reproducible and Automated Language Model Assessment ([GitHub](https://github.com/WeOpenML/PandaLM)) |
| 4.29 | Can ChatGPT Pass An Introductory Level Functional Language Programming Course? ([arXiv](https://arxiv.org/abs/2305.02230)), ([PDF](https://arxiv.org/pdf/2305.02230.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.02230)) |
| 4.29 | A Review of ChatGPT Applications in Education, Marketing, Software Engineering, and Healthcare: Benefits, Drawbacks, and Research Directions ([arXiv](https://arxiv.org/abs/2305.00237)), ([PDF](https://arxiv.org/pdf/2305.00237.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.00237)) |
| 4.29 | ChatGPT-2D, which can generate mind maps with AI - ([Tweet](https://twitter.com/eyishazyer/status/1652215468005146626)), ([ChatGPT-2D](https://superusapp.com/chatgpt2d/)) |
| 4.29 | MLC LLM - an open framework that brings language models (LLMs) directly into a broad class of platforms (CUDA, Vulkan, Metal) with GPU acceleration ([Tweet](https://twitter.com/bohanhou1998/status/1652151502012837890)), ([Demo](https://mlc.ai/mlc-llm/)), ([GitHub](https://github.com/mlc-ai/mlc-llm)) |
| 4.29 | GenOs Index - The April (aka the Frenetic Pace) Edition - ([blog](https://www.decibel.vc/articles/genos-index-the-april-aka-the-frenetic-pace-edition)) |
| 4.29 | StableVicuna, the AI World’s First Open Source RLHF LLM Chatbot! - ([Blog](https://stability.ai/blog/stablevicuna-open-source-rlhf-chatbot)), ([Tweet](https://twitter.com/StabilityAI/status/1652026192193785856)) |
| 4.29 | DeepFloyd - a state-of-the-art text-to-image model ([Web](https://deepfloyd.ai/deepfloyd-if)), ([GitHub](https://github.com/deep-floyd/IF)), ([HuggingFace demo](https://huggingface.co/spaces/DeepFloyd/IF)), ([Tweet](https://twitter.com/deepfloydai/status/1651983493717532673)) |
| 4.29 | When Patient Questions Are Answered With Higher Quality and Empathy by ChatGPT than Physicians - ([Blog](https://erictopol.substack.com/p/when-patient-questions-are-answered)) |
| 4.29 | BMTools - Tool Learning for Big Models, Open-Source Solutions of ChatGPT-Plugins ([GitHub](https://github.com/openbmb/bmtools)) |
| 4.29 | FastChat-T5 ([GitHub](https://github.com/lm-sys/FastChat#FastChat-T5)), ([Tweet](https://twitter.com/lmsysorg/status/1652037026705985537)) |
| 4.29 | Lamini, the LLM Engine for Rapidly Customizing Models - ([Blog](https://lamini.ai/blog/introducing-lamini)) |
| 4.28 | EU proposes new copyright rules for generative AI - ([Reuter](https://www.reuters.com/technology/eu-lawmakers-committee-reaches-deal-artificial-intelligence-act-2023-04-27/)), ([Economic times](https://www.reuters.com/technology/eu-lawmakers-committee-reaches-deal-artificial-intelligence-act-2023-04-27/)) | 
| 4.28 | PROMPTENGINEERING FORCHATGPTA QUICKGUIDE TOTECHNIQUES, TIPS,ANDBESTPRACTICES - ([PDF](https://www.techrxiv.org/articles/preprint/Prompt_Engineering_For_ChatGPT_A_Quick_Guide_To_Techniques_Tips_And_Best_Practices/22683919)) |
| 4.28 | ResiDual: Transformer with Dual Residual Connections ([arXiv](https://arxiv.org/abs/2304.14802)), ([PDF](https://arxiv.org/pdf/2304.14802.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.14802)), ([GitHub](https://github.com/microsoft/ResiDual)) |
| 4.28 | Causal Reasoning and Large Language Models: Opening a New Frontier for Causality ([arXiv](https://arxiv.org/abs/2305.00050)), ([PDF](https://arxiv.org/pdf/2305.00050.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.00050)) |
| 4.28 | We Interviewed the Engineer Google Fired for Saying Its AI Had Come to Life ([Futurism](https://futurism.com/blake-lemoine-google-interview)) |
| 4.28 | LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model ([arXiv](https://arxiv.org/abs/2304.15010)), ([PDF](https://arxiv.org/pdf/2304.15010.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.15010)), ([GitHub](https://github.com/ZrrSkywalker/LLaMA-Adapter)) |
| 4.28 | MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks ([arXiv](https://arxiv.org/abs/2304.14979)), ([PDF](https://arxiv.org/pdf/2304.14979.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.14979)) |
| 4.28 | Are Emergent Abilities of Large Language Models a Mirage? ([arXiv](https://arxiv.org/abs/2304.15004)), ([PDF](https://arxiv.org/pdf/2304.15004.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.15004)) |
| 4.28 | The Ultimate Battle of Language Models: Lit-LLaMA vs GPT3.5 vs Bloom vs …. ([Blog](https://lightning.ai/pages/community/community-discussions/the-ultimate-battle-of-language-models-lit-llama-vs-gpt3.5-vs-bloom-vs/)) |
| 4.28 | Otter, a multi-modal in-context learning model with instruction tuning - ([GitHub](https://github.com/Luodian/otter)), ([Demo](https://otter.cliangyu.com/)), ([Youtube](https://www.youtube.com/watch?v=r-YM4DGGAdE)) |
| 4.28 | [Economist](https://www.economist.com/by-invitation/2023/04/28/yuval-noah-harari-argues-that-ai-has-hacked-the-operating-system-of-human-civilisation) - Yuval Noah Harari argues that AI has hacked the operating system of human civilisation ([Archive](https://archive.is/HGRsq#selection-1039.0-1039.86)) |
| 4.28 | Assessing the Potential of USMLE-Like Exam Questions Generated by GPT-4 ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.04.25.23288588v1)), ([PDF](https://www.medrxiv.org/content/10.1101/2023.04.25.23288588v1.full.pdf)) |
| 4.28 | JAMA - Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum - ([paper](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2804309?guestAccessKey=6d6e7fbf-54c1-49fc-8f5e-ae7ad3e02231&utm_source=For_The_Media&utm_medium=referral&utm_campaign=ftm_links&utm_content=tfl&utm_term=042823)) |
| 4.27 | ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger ([arXiv](https://arxiv.org/abs/2304.14475)), ([PDF](https://arxiv.org/pdf/2304.14475.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.14475)) |
| 4.27 | PMC-LLaMA: Further Finetuning LLaMA on Medical Papers ([arXiv](https://arxiv.org/abs/2304.14454)), ([PDF](https://arxiv.org/pdf/2304.14454.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.14454)), ([GitHub](https://github.com/chaoyi-wu/PMC-LLaMA)) |
| 4.27 | "Can ChatGPT Diagnose Me?" How Large Language Models will Transform Clinical Care - ([Youtube](https://www.youtube.com/playlist?list=PLe6zdIMe5B7JWokb0Vvket4M3h-0KvBNn)) |
| 4.27 | Large Language Models Are State-of-the-Art Evaluators of Code Generation ([arXiv](https://arxiv.org/abs/2304.14317)), ([PDF](https://arxiv.org/pdf/2304.14317.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.14317)) |
| 4.27 | Controlled Text Generation with Natural Language Instructions  ([arXiv](https://arxiv.org/abs/2303.14293)), ([PDF](https://arxiv.org/pdf/2303.14293.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.14293)) |
| 4.27 | A Survey of Large Language Models - version 8 ([arXiv](https://arxiv.org/abs/2303.18223)), ([PDF](https://arxiv.org/pdf/2303.18223.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.18223)) |
| 4.27 | LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions ([arXiv](https://arxiv.org/abs/2304.14402)), ([PDF](https://arxiv.org/pdf/2304.14402.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.14402)), ([GitHub](https://github.com/m)) |
| 4.27 | DataComp: In search of the next generation of multimodal datasets ([arXiv](https://arxiv.org/abs/2304.14108)), ([PDF](https://arxiv.org/pdf/2304.14108.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.14108)), ([GitHub](https://github.com/mlfoundations/datacomp)), ([Project page](https://www.datacomp.ai/)) |
| 4.27 | We're Afraid Language Models Aren't Modeling Ambiguity ([arXiv](https://arxiv.org/abs/2304.14399)), ([PDF](https://arxiv.org/pdf/2304.14399.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.14399)) |
| 4.27 | Boston Dynamics robot dog can answer your questions now, thanks to ChatGPT - ([ZDNet](https://www.zdnet.com/article/boston-dynamics-robot-dog-can-answer-your-questions-now-thanks-to-chatgpt/)), ([YouTube](https://www.youtube.com/watch?v=Y1-s37zrm1M)) |
| 4.27 | LlamaIndex & Deep Lake for Financial Statement Analysis ([Blog](https://medium.com/@jerryjliu98/llamaindex-deep-lake-for-financial-statement-analysis-954f2b789c8e)) |
| 4.26 | Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning ([arXiv](https://arxiv.org/abs/2304.13653)), ([PDF](https://arxiv.org/pdf/2304.13653.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13653)) |
| 4.26 | Multidimensional Evaluation for Text Style Transfer Using ChatGPT ([arXiv](https://arxiv.org/abs/2304.13462)), ([PDF](https://arxiv.org/pdf/2304.13462.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13462)) |
| 4.26 | NPJ - Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers ([Paper](https://www.nature.com/articles/s41746-023-00819-6)), ([PDF](https://www.nature.com/articles/s41746-023-00819-6.pdf)) |
| 4.26 | [TopGPT](https://www.topgpt.io/) — the world’s first Andrew Tate large language model |
| 4.26 | Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models ([arXiv](https://arxiv.org/abs/2304.13835)), ([PDF](https://arxiv.org/pdf/2304.13835.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13835)) |
| 4.26 | MOSS, a 16B tool-augmented conversational language model ([Tweet](https://twitter.com/tianxiangsun/status/1650895260493705216)), ([GitHub](https://github.com/OpenLMLab/MOSS)) |
| 4.26 | Exploring the Curious Case of Code Prompts ([arXiv](https://arxiv.org/abs/2304.13250)), ([PDF](https://arxiv.org/pdf/2304.13250.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13250)) |
| 4.26 | Controllable Image Generation via Collage Representations ([arXiv](https://arxiv.org/abs/2304.13722)), ([PDF](https://arxiv.org/pdf/2304.13722.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13722)) |
| 4.26 | Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System ([arXiv](https://arxiv.org/abs/2304.13343)), ([PDF](https://arxiv.org/pdf/2304.13343.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13343)) |
| 4.26 | TextDeformer: Geometry Manipulation using Text Guidance ([arXiv](https://arxiv.org/abs/2304.13348)), ([PDF](https://arxiv.org/pdf/2304.13348.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13348)) |
| 4.26 | Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery ([arXiv](https://arxiv.org/abs/2304.13714)), ([PDF](https://arxiv.org/pdf/2304.13714.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13714)) |
| 4.26 | Ray Conditioning: Trading Photo-consistency for Photo-realism in Multi-view Image Generation ([arXiv](https://arxiv.org/abs/2304.13681)), ([PDF](https://arxiv.org/pdf/2304.13681.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13681)), ([Project page](https://ray-cond.github.io/)) |
| 4.26 | Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond ([arXiv](https://arxiv.org/abs/2304.13712)), ([PDF](https://arxiv.org/pdf/2304.13712.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13712)), ([GitHub](https://github.com/Mooler0410/LLMsPracticalGuide)) |
| 4.26 | [HuggingChat](https://huggingface.co/chat/) - the first open source alternative to ChatGPT |
| 4.25 | [Time](https://time.com/6273743/thinking-that-could-doom-us-with-ai/) - The 'Don't Look Up' Thinking That Could Doom Us With AI ([Archive](https://archive.is/gMi8q)) |
| 4.25 | AI-assisted coding: Experiments with GPT-4 ([arXiv](https://arxiv.org/abs/2304.13187)), ([PDF](https://arxiv.org/pdf/2304.13187.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13187)) |
| 4.25 | NVIDIA NeMo Guardrails helps enterprises keep applications built on large language models aligned with their safety and security requirements ([Blog](https://blogs.nvidia.com/blog/2023/04/25/ai-chatbot-guardrails-nemo/)), ([GitHub](https://github.com/NVIDIA/NeMo-Guardrails)) |
| 4.25 | Stable and low-precision training for large-scale vision-language models ([arXiv](https://arxiv.org/abs/2304.13013)), ([PDF](https://arxiv.org/pdf/2304.13013.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13013)) |
| 4.25 | AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head ([arXiv](https://arxiv.org/abs/2304.12995)), ([PDF](https://arxiv.org/pdf/2304.12995.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12995)) |
| 4.25 | Answering Questions by Meta-Reasoning over Multiple Chains of Thought ([arXiv](https://arxiv.org/abs/2304.13007)), ([PDF](https://arxiv.org/pdf/2304.13007.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13007)) |
| 4.25 | Patch-based 3D Natural Scene Generation from a Single Example ([arXiv](https://arxiv.org/abs/2304.12670)), ([PDF](https://arxiv.org/pdf/2304.12670.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12670)), ([Project page](http://weiyuli.xyz/Sin3DGen/))  |
| 4.25 | Generative AI at Work - ([NBER](https://www.nber.org/papers/w31161)), ([PDF](https://www.nber.org/system/files/working_papers/w31161/w31161.pdf)) | 
| 4.25 | [Chatbot Arena](https://chat.lmsys.org/?arena) |
| 4.24 | Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model ([arXiv](https://arxiv.org/abs/2304.13731)), ([PDF](https://arxiv.org/pdf/2304.13731.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.13731)),([Project page](https://tango-web.github.io/)), ([GitHub](https://github.com/declare-lab/tango)) |
| 4.24 | AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays ([arXiv](https://arxiv.org/abs/2304.14276)), ([PDF](https://arxiv.org/pdf/2304.14276.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.14276)) |
| 4.24 | Pointersect: Neural Rendering with Cloud-Ray Intersection ([arXiv](https://arxiv.org/abs/2304.12390)), ([PDF](https://arxiv.org/pdf/2304.12390.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12390)), ([web](https://machinelearning.apple.com/research/pointersect)) |
| 4.24 | A Cookbook of Self-Supervised Learning  ([arXiv](https://arxiv.org/abs/2304.12210)), ([PDF](https://arxiv.org/pdf/2304.12210.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12210)) |
| 4.24 | On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research ([arXiv](https://arxiv.org/abs/2304.12397)), ([PDF](https://arxiv.org/pdf/2304.12397.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12397)), ([GitHub](https://github.com/for-ai/black-box-api-challenges)) |
| 4.24 | Towards Realistic Generative 3D Face Models ([arXiv](https://arxiv.org/abs/2304.12483)), ([PDF](https://arxiv.org/pdf/2304.12483.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12483)) |
| 4.24 | TextMesh: Generation of Realistic 3D Meshes From Text Prompts ([arXiv](https://arxiv.org/abs/2304.12439)), ([PDF](https://arxiv.org/pdf/2304.12439.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12439)) |
| 4.24 | Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training Exam (TXIT): Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology ([arXiv](https://arxiv.org/abs/2304.11957)), ([PDF](https://arxiv.org/pdf/2304.11957.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11957)), ([GitHub](https://github.com/yixinghuang/chatgpt-benchmark-on-radiation-oncology)) |
| 4.24 | Social AGI - SAMANTHA (Self-Reflective Artificial Mind Attuned to Naturalistic Thought and Human Adaptability) ([GitHub](https://github.com/Methexis-Inc/SocialAGI)) |
| 4.24 | Segment Anything in Medical Images ([arXiv](https://arxiv.org/abs/2304.12306)), ([PDF](https://arxiv.org/pdf/2304.12306.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12306)), ([GitHub](https://github.com/bowang-lab/MedSAM)) |
| 4.24 | Segment Anything in 3D with NeRFs  ([arXiv](https://arxiv.org/abs/2304.12308)), ([PDF](https://arxiv.org/pdf/2304.12308.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12308)), ([project page](https://jumpat.github.io/SA3D/)) |
| 4.24 | WizardLM: Empowering Large Language Models to Follow Complex Instructions ([arXiv](https://arxiv.org/abs/2304.12244)), ([PDF](https://arxiv.org/pdf/2304.12244.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12244)) |
| 4.24 | Track Anything: Segment Anything Meets Videos ([arXiv](https://arxiv.org/abs/2304.11968)), ([PDF](https://arxiv.org/pdf/2304.11968.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11968)) |
| 4.24 | OpenAI Brand guidelines - ([blog](https://openai.com/brand)) |
| 4.24 | GPT4Tools: Teaching LLM to Use Tools via Self-instruction - ([Project page](https://gpt4tools.github.io/)), ([Github](https://github.com/StevenGrove/GPT4Tools)), ([Video](https://www.youtube.com/watch?v=Qrj94ibQIT8)),  |
| 4.24 | RAM: Relate-Anything-Model ([GitHub](https://github.com/Luodian/RelateAnything)), ([Demo](https://huggingface.co/spaces/mmlab-ntu/relate-anything-model)) |
| 4.24 | [Chart-GPT 1.0](https://www.chartgpt.dev/) |
| 4.23 | Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models ([arXiv](https://arxiv.org/abs/2304.11657)), ([PDF](https://arxiv.org/pdf/2304.11657.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11657)), ([GitHub](https://github.com/GasolSun36/Iter-CoT)) |
| 4.23 | Evaluating ChatGPT's Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness ([arXiv](https://arxiv.org/abs/2304.11633)), ([PDF](https://arxiv.org/pdf/2304.11633.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11633)) |
| 4.22 | Boosting Theory-of-Mind Performance in Large Language Models via Prompting  ([arXiv](https://arxiv.org/abs/2304.11490)), ([PDF](https://arxiv.org/pdf/2304.11490.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11490)) |
| 4.22 | LaMP: When Large Language Models Meet Personalization ([arXiv](https://arxiv.org/abs/2304.11406)), ([PDF](https://arxiv.org/pdf/2304.11406.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11406)), ([Project page](https://lamp-benchmark.github.io/index.html)), ([Download](https://lamp-benchmark.github.io/download)), ([Leaderboard](https://lamp-benchmark.github.io/leaderboard)), ([GitHub](https://github.com/LaMP-Benchmark/LaMP)) |
| 4.22 | Finetuning Large Language Models ([Blog](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)) |
| 4.21 | Can GPT-4 Perform Neural Architecture Search? ([arXiv](https://arxiv.org/abs/2304.10970)), ([PDF](https://arxiv.org/pdf/2304.10970.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.10970)) |
| 4.21 | Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition ([arXiv](https://arxiv.org/abs/2304.10977)), ([PDF](https://arxiv.org/pdf/2304.10977.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.10977)) |
| 4.21 | Emergent and Predictable Memorization in Large Language Models  ([arXiv](https://arxiv.org/abs/2304.11158)), ([PDF](https://arxiv.org/pdf/2304.11158.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11158)) |
| 4.21 | CLaMP: Contrastive Language-Music Pre-training for Cross-Modal Symbolic Music Information Retrieval  ([arXiv](https://arxiv.org/abs/2304.11029)), ([PDF](https://arxiv.org/pdf/2304.11029.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11029)) |
| 4.21 | Bard now helps you code with support for 20+ langs (Python, C++, JS, Go, etc.). ([Blog](https://blog.google/technology/ai/code-with-bard/)) |
| 4.21 | Inducing anxiety in large language models increases exploration and bias ([arXiv](https://arxiv.org/abs/2304.11111)), ([PDF](https://arxiv.org/pdf/2304.11111.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11111)) |
| 4.20 | Why Does ChatGPT Fall Short in Answering Questions Faithfully? ([arXiv](https://arxiv.org/abs/2304.10513)), ([PDF](https://arxiv.org/pdf/2304.10513.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.10513)) |
| 4.20 | [FinChat.io](https://finchat.io/chats/) - The Chat GPT for Finance |
| 4.20 | LlamaAcademy: Teaching Llamas How to Code ([GitHub](https://github.com/danielgross/LlamaAcademy)) |
| 4.20 | Announcing Google DeepMind: DeepMind + Brain = Google DeepMind ([Blog](https://www.deepmind.com/blog/announcing-google-deepmind)) |
| 4.20 | "Can ChatGPT Diagnose Me?" How Large Language Models will Transform Clinical Care. Thursday, April 27th, 2023 ([RSVP](https://aimi.stanford.edu/events/can-chatgpt-diagnose-me-how-large-language-models-will-transform-clinical-care)) |
| 4.20 | StableLM: Stability AI Language Models ([GitHub](https://github.com/stability-AI/stableLM/)), ([Blog](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)) |
| 4.19 | Fundamental Limitations of Alignment in Large Language Models ([arXiv](https://arxiv.org/abs/2304.11082)), ([PDF](https://arxiv.org/pdf/2304.11082.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11082)) |
| 4.19 | Scaling Transformer to 1M tokens and beyond with RMT ([arXiv](https://arxiv.org/abs/2304.11062)), ([PDF](https://arxiv.org/pdf/2304.11062.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11062)), ([Github](https://github.com/booydar/t5-experiments/tree/scaling-report)) |
| 4.19 | Occupational Heterogeneity in Exposure to Generative AI - ([paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4414065)), ([PDF](https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID4414065_code2763040.pdf?abstractid=4414065&mirid=1)) |
| 4.19 | The Unintended Consequences of Censoring Digital Technology -- Evidence from Italy's ChatGPT Ban ([arXiv](https://arxiv.org/abs/2304.09339)), ([PDF](https://arxiv.org/pdf/2304.09339.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09339)) |
| 4.19 | CompressGPT: Decrease Token Usage by ~70% ([blog](https://musings.yasyf.com/compressgpt-decrease-token-usage-by-70/)) |
| 4.19 | Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes ([arXiv](https://arxiv.org/abs/2304.09433)), ([PDF](https://arxiv.org/pdf/2304.09433.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09433)), ([Github](https://github.com/HazyResearch/evaporate)) |
| 4.19 | LLM as A Robotic Brain: Unifying Egocentric Memory and Control ([arXiv](https://arxiv.org/abs/2304.09349)), ([PDF](https://arxiv.org/pdf/2304.09349.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09349)) |
| 4.19 | Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent ([arXiv](https://arxiv.org/abs/2304.09542)), ([PDF](https://arxiv.org/pdf/2304.09542.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09542)) |
| 4.19 | Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models ([arXiv](https://arxiv.org/abs/2304.09842)), ([PDF](https://arxiv.org/pdf/2304.09842.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09842)), ([project page](https://chameleon-llm.github.io/)), ([GitHub](https://github.com/lupantech/chameleon-llm)) |
| 4.19 | h2oai's LLM repositories - ([h2ogpt](https://github.com/h2oai/h2ogpt)), ([h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio)), ([Huggingface](https://huggingface.co/h2oai)) | 
| 4.19 | Evaluating Verifiability in Generative Search Engines ([arXiv](https://arxiv.org/abs/2304.09848)), ([PDF](https://arxiv.org/pdf/2304.09848.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09848)) |
| 4.19 | How to train your own Large Language Models ([Blog](https://blog.replit.com/llm-training)) |
| 4.19 | [AI Playground](https://play.vercel.ai/r/mWjP5Dt) from Vercel Labs ([tweet](https://twitter.com/vercel/status/1648451494440742917)) |
| 4.19 | StanfordBDHG HealthGPT ([tweet](https://twitter.com/varunshenoy_/status/1648374949537775616)), ([GitHub](https://github.com/StanfordBDHG/HealthGPT)) |
| 4.19 | GPT4All-J : the first Apache-2 Licensed Chatbot that runs locally on your machine ([GitHub](https://github.com/nomic-ai/gpt4all)), ([PDF](https://static.nomic.ai/gpt4all/2023_GPT4All-J_Technical_Report_2.pdf)) | 
| 4.19 | PersonalPrivate.AI - system to advise on new patent ideas ([tweet](https://twitter.com/BrianRoemmele/status/1648378237633073152)) |
| 4.18 | [Economist](https://www.economist.com/by-invitation/2023/04/18/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts) - The world needs an international agency for artificial intelligence, say two AI experts ([Archive](https://archive.is/jWEJ8#selection-1039.0-1039.87)) |
| 4.18 | CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models ([arXiv](https://arxiv.org/abs/2304.10946)), ([PDF](https://arxiv.org/pdf/2304.10946.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.10946)) |
| 4.18 | Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions ([arXiv](https://arxiv.org/abs/2304.11063)), ([PDF](https://arxiv.org/pdf/2304.11063.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.11063)) |
| 4.18 | Nature - [Why open-source generative AI models are an ethical way forward for science](https://www.nature.com/articles/d41586-023-01295-4) |
| 4.18 | Autonomous Agents(BabyAGI, AutoGPT) & Agent Simulations(CAMEL, Generative Agents) ([Blog](https://blog.langchain.dev/agents-round/)) |
| 4.18 | AutoTaskFormer: Searching Vision Transformers for Multi-task Learning ([arXiv](https://arxiv.org/abs/2304.08756)), ([PDF](https://arxiv.org/pdf/2304.08756.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08756)) |
| 4.18 | SAM Fails to Segment Anything? -- SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More ([arXiv](https://arxiv.org/abs/2304.09148)), ([PDF](https://arxiv.org/pdf/2304.09148.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09148)), ([Project page](https://tianrun-chen.github.io/SAM-Adaptor/)) |
| 4.18 | Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models ([arXiv](https://arxiv.org/abs/2304.08818)), ([PDF](https://arxiv.org/pdf/2304.08818.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08818)), ([Project page](https://research.nvidia.com/labs/toronto-ai/VideoLDM/)) | 
| 4.18 | Google - Differentially private heatmaps ([Blog](https://ai.googleblog.com/2023/04/differentially-private-heatmaps.html)) |
| 4.18 | [The Complete Beginners Guide To Autonomous Agents](https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents) |
| 4.18 | Llama Lab - A repo dedicated to building cutting-edge AGI projects: llama_agi (inspired by babyagi) and auto_llama (inspired by autogpt) ([GitHub](https://github.com/run-llama/llama-lab)), ([Llama Hub](https://llamahub.ai/)) |
| 4.18 | Elon Musk to start ChatGPT rival called “TruthGPT” ([tweet](https://twitter.com/theLionary/status/1648088563874156545)) |
| 4.17 | Notice of the Cyberspace Administration of China on Public Comments on the "Administrative Measures for Generative Artificial Intelligence Services (Draft for Comment)" ([Announcement](http://www.cac.gov.cn/2023-04/11/c_1682854275475410.htm)) |
| 4.17 | Pretrained Language Models as Visual Planners for Human Assistance ([arXiv](https://arxiv.org/abs/2304.09179)), ([PDF](https://arxiv.org/pdf/2304.09179.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09179)) |
| 4.17 | An Evaluation on Large Language Model Outputs: Discourse and Memorization ([arXiv](https://arxiv.org/abs/2304.08637)), ([PDF](https://arxiv.org/pdf/2304.08637.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08637)) |
| 4.17 | [Epic, Microsoft bring generative AI to EHRs](https://digitalhealth.modernhealthcare.com/digital-health/himss23-epic-microsoft-bring-openais-gpt-4-ehrs) - ([Microsoft announcement](Microsoft and Epic expand strategic collaboration with integration of Azure OpenAI Service)) |
| 4.17 | BenchMD: A Benchmark for Modality-Agnostic Learning on Medical Images and Sensors ([arXiv](https://arxiv.org/abs/2304.08486)), ([PDF](https://arxiv.org/pdf/2304.08486.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08486)) | 
| 4.17 | Towards Robust Prompts on Vision-Language Models ([arXiv](https://arxiv.org/abs/2304.08479)), ([PDF](https://arxiv.org/pdf/2304.08479.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08479)) | 
| 4.17 | Tool Learning with Foundation Models ([arXiv](https://arxiv.org/abs/2304.08354)), ([PDF](https://arxiv.org/pdf/2304.08354.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08354)), ([GitHub](https://github.com/OpenBMB/BMTools)) | 
| 4.17 | Low-code LLM: Visual Programming over LLMs ([arXiv](https://arxiv.org/abs/2304.08103)), ([PDF](https://arxiv.org/pdf/2304.08103.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08103)) |
| 4.17 | Wired - [OpenAI’s CEO Says the Age of Giant AI Models Is Already Over](https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/) |
| 4.17 | Synthetic Data from Diffusion Models Improves ImageNet Classification ([arXiv](https://arxiv.org/abs/2304.08466)), ([PDF](https://arxiv.org/pdf/2304.08466.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08466)) |
| 4.17 | RedPajama-Data: An Open Source Recipe to Reproduce LLaMA training dataset ([GitHib](https://github.com/togethercomputer/RedPajama-Data)) |
| 4.17 | Visual Instruction Tuning  ([arXiv](https://arxiv.org/abs/2304.08485)), ([PDF](https://arxiv.org/pdf/2304.08485.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08485)), ([GitHub](https://github.com/haotian-liu/LLaVA)), ([Dataset](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)), ([Model](https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0)), ([Project page](https://llava-vl.github.io/)), ([Demo](https://llava.hliu.cc/)) |
| 4.17 | Learning to Compress Prompts with Gist Tokens ([arXiv](https://arxiv.org/abs/2304.08467)), ([PDF](https://arxiv.org/pdf/2304.08467.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08467)) |
| 4.17 | ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT ([arXiv](https://arxiv.org/abs/2304.08448)), ([PDF](https://arxiv.org/pdf/2304.08448.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.08448)) |
| 4.17 | Meta - DINOv2: State-of-the-art computer vision models with self-supervised learning ([blog](https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/)), ([GitHub](https://github.com/facebookresearch/dinov2)), ([Demo](https://dinov2.metademolab.com/)), ([arXiv](https://arxiv.org/abs/2304.07193)), ([PDF](https://arxiv.org/pdf/2304.07193.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.07193)) |
| 4.17 | [TypingMind](https://www.typingmind.com/) - A better UI for ChatGPT ([tweet](https://twitter.com/tdinh_me/status/1647820035820523523)) |
| 4.16 | Understanding Large Language Models ([Blog](https://magazine.sebastianraschka.com/p/understanding-large-language-models)) |
| 4.16 | INSIGHT - an autonomous AI that can do medical research ([GitHub](https://github.com/oneil512/INSIGHT)) |
| 4.16 | GPT4free - use ChatGPT, for free!! - ([GitHub](https://github.com/xtekky/gpt4free)) | 
| 4.16 | Solving Math Word Problems by Combining Language Models With Symbolic Solvers ([arXiv](https://arxiv.org/abs/2304.09102)), ([PDF](https://arxiv.org/pdf/2304.09102.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09102)) |
| 4.16 | ChatPLUG: Open-Domain Generative Dialogue System with Internet-Augmented Instruction Tuning for Digital Human ([arXiv](https://arxiv.org/abs/2304.07849)), ([PDF](https://arxiv.org/pdf/2304.07849.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.07849)) |
| 4.16 | Driving and suppressing the human language network using large language models ([bioRxiv](https://www.biorxiv.org/content/10.1101/2023.04.16.537080v1)), ([PDF](https://www.biorxiv.org/content/10.1101/2023.04.16.537080v1.full.pdf)) |
| 4.16 | MultiGPT ([GitHub](https://github.com/rumpfmax/Multi-GPT)). ([tweet](https://twitter.com/md_rumpf/status/1647911393796956162)) |
| 4.16 | OpenAssistant Conversations - Democratizing Large Language Model Alignment ([PDF](https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view)), ([YouTube](https://www.youtube.com/watch?v=Ft9_RsKxrG4)), ([hacker news](https://news.ycombinator.com/item?id=35582417)) |
| 4.16 | Auto-evaluator - lightweight evaluation tool for question-answering using Langchain ([GitHub](https://github.com/PineappleExpress808/auto-evaluator)) | 
| 4.16 | NYT - [Google Devising Radical Search Changes to Beat Back A.I. Rivals](https://www.nytimes.com/2023/04/16/technology/google-search-engine-ai.html) ([Archive](https://archive.is/ti9Ns)) |
| 4.15 | [Graphologue](https://twitter.com/HaijunXia/status/1646917869115166720) and [Sensecape](https://twitter.com/HaijunXia/status/1646919380704559104) by [UCSD Creativity Lab](https://creativity.ucsd.edu/ai) |
| 4.15 | Tractable Control for Autoregressive Language Generation ([arXiv](https://arxiv.org/abs/2304.07438)), ([PDF](https://arxiv.org/pdf/2304.07438.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.07438)) |
| 4.15 | Web LLM - language model chats directly onto web browsers ([Site](https://mlc.ai/web-llm/)), ([GitHub](https://github.com/mlc-ai/web-llm#how)) |
| 4.15 | MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models ([Project page](https://minigpt-4.github.io/)). ([Paper]()), ([GitHub](https://github.com/Vision-CAIR/MiniGPT-4)), ([YouTube](https://www.youtube.com/watch?v=__tftoxpBAw)) |
| 4.15 | OpenAssistant - The world's largest open-source replication of ChatGPT ([site](https://open-assistant.io/)), ([GitHub](https://github.com/LAION-AI/Open-Assistant)), ([Dataset - OASST1](https://huggingface.co/datasets/OpenAssistant/oasst1)), ([Paper](https://ykilcher.com/oa-paper)), ([YouTube](https://www.youtube.com/watch?v=ddG2fM9i4Kk&feature=youtu.be)), ([Reddit](https://www.reddit.com/r/OpenAssistant/)) |
| 4.14 | ChatGPT: Applications, Opportunities, and Threats ([arXiv](https://arxiv.org/abs/2304.09103)), ([PDF](https://arxiv.org/pdf/2304.09103.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.09103)) |
| 4.14 | Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding ([arXiv](https://arxiv.org/abs/2304.06906)), ([PDF](https://arxiv.org/pdf/2304.06906.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06906)) |
| 4.14 | OpenBB Terminal V3.0.0rc2 - ([GitHub](https://github.com/OpenBB-finance/OpenBBTerminal/releases/tag/v3.0.0rc2)) |
| 4.14 | Delta Denoising Score  ([arXiv](https://arxiv.org/abs/2304.07090)), ([PDF](https://arxiv.org/pdf/2304.07090.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.07090)), ([Project page](https://delta-denoising-score.github.io/)) |
| 4.14 | DINOv2: Learning Robust Visual Features without Supervision ([arXiv](https://arxiv.org/abs/2304.07193)), ([PDF](https://arxiv.org/pdf/2304.07193.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.07193)) |
| 4.14 | Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text  ([arXiv](https://arxiv.org/abs/2304.06939)), ([PDF](https://arxiv.org/pdf/2304.06939.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06939)), ([GitHub](https://github.com/allenai/mmc4)) |
| 4.14 | WSJ - [Elon Musk Creates New Artificial Intelligence Company X.AI](https://www.wsj.com/articles/elon-musks-new-artificial-intelligence-business-x-ai-incorporates-in-nevada-962c7c2f) ([archive](https://archive.is/qzbbb)), ([FT](https://www.ft.com/content/2a96995b-c799-4281-8b60-b235e84aefe4)) |
| 4.14 | Google Med-PaLM 2 - [A responsible path to generative AI in healthcare](https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model?hl=en) |
| 4.14 | Meta's open source Animated Drawings - ([Blog](https://developers.facebook.com/blog/post/2023/04/13/meta-os-animated-drawings/)) |
| 4.14 | ControlNet v1.1 nightly - ([GitHub](https://github.com/lllyasviel/ControlNet-v1-1-nightly)) |
| 4.13 | Teenage-AGI ([GitHub](https://github.com/seanpixel/Teenage-AGI)) |
| 4.13 | Boosted Prompt Ensembles for Large Language Models ([arXiv](https://arxiv.org/abs/2304.05970)), ([PDF](https://arxiv.org/pdf/2304.05970.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.05970)) |
| 4.13 | ChatGPT-4 Outperforms Experts and Crowd Workers in Annotating Political Twitter Messages with Zero-Shot Learning ([arXiv](https://arxiv.org/abs/2304.06588)), ([PDF](https://arxiv.org/pdf/2304.06588.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06588)) |
| 4.13 | Soundini: Sound-Guided Diffusion for Natural Video Editing ([arXiv](https://arxiv.org/abs/2304.06818)), ([PDF](https://arxiv.org/pdf/2304.06818.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06818)), ([Project page](https://kuai-lab.github.io/soundini-gallery/)) |
| 4.13 | Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study ([arXiv](https://arxiv.org/abs/2304.06762)), ([PDF](https://arxiv.org/pdf/2304.06762.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06762)), ([GitHub](https://github.com/geekyutao/Inpaint-Anything)) |
| 4.13 | Inpaint Anything: Segment Anything Meets Image Inpainting ([arXiv](https://arxiv.org/abs/2304.06790)), ([PDF](https://arxiv.org/pdf/2304.06790.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06790)), ([GitHub](https://github.com/NVIDIA/Megatron-LM#retro)) |
| 4.13 | [GoalGPT](https://beta.nando.ai/goalgpt.php) by Nando.ai |
| 4.13 | Power-seeking can be probable and predictive for trained agents ([arXiv](https://arxiv.org/abs/2304.06528)), ([PDF](https://arxiv.org/pdf/2304.06528.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06528)) |
| 4.13 | [GoalGPT](https://beta.nando.ai/goalgpt.php) by Nando.ai |
| 4.13 | [Stable Diffusion XL Beta Available for API Customers and DreamStudio Users](https://stability.ai/blog/stable-diffusion-xl-beta-available-for-api-customers-and-dreamstudio-users) |
| 4.13 | [NAB 2023: Introducing Text-Based Editing in Premiere Pro, Properties panel in After Effects, and much more](https://blog.adobe.com/en/publish/2023/04/13/nab-2023-introducing-text-based-editing-premiere-pro-properties-panel-after-effects-more) |
| 4.13 | [Announcing New Tools for Building with Generative AI on AWS](https://aws.amazon.com/ko/blogs/machine-learning/announcing-new-tools-for-building-with-generative-ai-on-aws/) - Amazon LLM (Titan), AWS fine-tuning model (Bedrock), Amazon copilot competitor (Code whisperer) |
| 4.13 | FT - [We must slow down the race to God-like AI](https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2) ([archive](https://archive.is/jFfBQ#selection-1443.0-1443.41)) |
| 4.13 | Segment Everything Everywhere All at Once ([arXiv](https://arxiv.org/abs/2304.06718)), ([PDF](https://arxiv.org/pdf/2304.06718.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06718)) |
| 4.13 | Expressive Text-to-Image Generation with Rich Text ([arXiv](https://arxiv.org/abs/2304.06720)), ([PDF](https://arxiv.org/pdf/2304.06720.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06720)), ([Project page](https://rich-text-to-image.github.io/)) |
| 4.13 | AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models ([arXiv](https://arxiv.org/abs/2304.06364)), ([PDF](https://arxiv.org/pdf/2304.06364.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06364)), ([GitHub](https://github.com/microsoft/AGIEval)) |
| 4.12 | Can Large Language Models Transform Computational Social Science? ([arXiv](https://arxiv.org/abs/2305.03514)), ([PDF](https://arxiv.org/pdf/2305.03514.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2305.03514)) | 
| 4.12 | Galactic ChitChat: Using Large Language Models to Converse with Astronomy Literature ([arXiv](https://arxiv.org/abs/2304.05406)), ([PDF](https://arxiv.org/pdf/2304.05406.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.05406)) | 
| 4.12 | Performance of ChatGPT, GPT-4, and Google Bard on a Neurosurgery Oral Boards Preparation Question Bank ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.04.06.23288265v1)), ([PDF](https://www.medrxiv.org/content/10.1101/2023.04.06.23288265v1.full.pdf)) |
| 4.12 | ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning ([arXiv](https://arxiv.org/abs/2304.05613)), ([PDF](https://arxiv.org/pdf/2304.05613.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.05613)) |
| 4.12 | Nature -[Foundation models for generalist medical artificial intelligence](https://www.nature.com/articles/s41586-023-05881-4) ([PDF](https://www.nature.com/articles/s41586-023-05881-4.pdf)) |
| 4.12 | Dolly v2 - 12B parameter language model ([Model weight](https://huggingface.co/databricks/dolly-v2-12b)), ([GitHub](https://github.com/databrickslabs/dolly/tree/master/data)), ([Blog](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)) | 
| 4.11 | Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond ([arXiv](https://arxiv.org/abs/2304.04968)), ([PDF](https://arxiv.org/pdf/2304.04968.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.04968)), ([Project page](https://perp-neg.github.io/)), ([GitHub](https://github.com/Perp-Neg/Perp-Neg-stablediffusion)), ([Colab](https://github.com/Perp-Neg/Perp-Neg-stablediffusion/blob/main/notebooks/demo.ipynb)), ([Hugging face](https://huggingface.co/spaces/rezaarmand/Perp-Neg)) | 
| 4.11 | Toxicity in ChatGPT: Analyzing Persona-assigned Language Models ([arXiv](https://arxiv.org/abs/2304.05335)), ([PDF](https://arxiv.org/pdf/2304.05335.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.05335)) | 
| 4.11 | Multi-step Jailbreaking Privacy Attacks on ChatGPT ([arXiv](https://arxiv.org/abs/2304.05197)), ([PDF](https://arxiv.org/pdf/2304.05197.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.05197)) | 
| 4.11 | [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html) |
| 4.11 | Emergent autonomous scientific research capabilities of large language models ([arXiv](https://arxiv.org/abs/2304.05332)), ([PDF](https://arxiv.org/pdf/2304.05332.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.05332)) |
| 4.11 | [OpenAI’s Bug Bounty Program](https://openai.com/blog/bug-bounty-program) |
| 4.11 | [NTIA’s “AI Accountability Policy Request for Comment”](https://ntia.gov/issues/artificial-intelligence/request-for-comments) |
| 4.11 | WSJ - [Biden Administration Weighs Possible Rules for AI Tools Like ChatGPT](https://www.wsj.com/amp/articles/biden-administration-weighs-possible-rules-for-ai-tools-like-chatgpt-46f8257b?fbclid=IwAR1GauvAq8cuHIQQlZ8dlxiKkYuszBMPHqr_K6iZiAeTz2yCjGu9vP_S3cc), ([archive](https://archive.is/6phfS)) |
| 4.11 | ChemCrow: Augmenting large-language models with chemistry tools ([arXiv](https://arxiv.org/abs/2304.05376)), ([PDF](https://arxiv.org/pdf/2304.05376.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.05376)) |
| 4.11 | [LangChainJS Support for Multiple JS Environments](https://blog.langchain.dev/js-envs/) ([tweet](https://twitter.com/LangChainAI/status/1645831073358815232)) |
| 4.11 | Teaching Large Language Models to Self-Debug ([arXiv](https://arxiv.org/abs/2304.05128)), ([PDF](https://arxiv.org/pdf/2304.05128.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.05128)) |
| 4.10 | On the Possibilities of AI-Generated Text Detection ([arXiv](https://arxiv.org/abs/2304.04736)), ([PDF](https://arxiv.org/pdf/2304.04736.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.04736)) |
| 4.10 | OpenAGI: When LLM Meets Domain Experts ([arXiv](https://arxiv.org/abs/2304.04370)), ([PDF](https://arxiv.org/pdf/2304.04370.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.04370)), ([GitHub](https://github.com/agiresearch/OpenAGI)) |
| 4.9 | BabyAGI JS - ([GitHub](https://github.com/ericciarla/babyagijs)) |
| 4.9 | AgentGPT - Auto-GPT directly in the browser ([tweet](https://twitter.com/asimdotshrestha/status/1644883727707959296)), ([GitHub](https://github.com/reworkd/AgentGPT)), ([demo](https://agentgpt.reworkd.ai/)) |
| 4.8 | [A Recipe for Training Large Models](https://wandb.ai/craiyon/report/reports/Recipe-Training-Large-Models--VmlldzozNjc4MzQz) |
| 4.7 | [SuperPrompt Engineer Encourages ChatGPT Hallucinations](https://metanews.com/superprompt-engineer-encourages-chatgpt-hallucinations/) |
| 4.7 | Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster ([arXiv](https://arxiv.org/abs/2304.03208)), ([PDF](https://arxiv.org/pdf/2304.03208.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.03208)) |
| 4.7 | Why think step-by-step? Reasoning emerges from the locality of experience ([arXiv](https://arxiv.org/abs/2304.03843)), ([PDF](https://arxiv.org/pdf/2304.03843.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.03843)) |
| 4.7 | Generative Agents: Interactive Simulacra of Human Behavior ([arXiv](https://arxiv.org/abs/2304.03442)), ([PDF](https://arxiv.org/pdf/2304.03442.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.03442)), ([Project](https://reverie.herokuapp.com/arXiv_Demo/)) | 
| 4.7 | Vicuna-7B: small, efficient, yet capable ([GitHub](https://github.com/lm-sys/FastChat)), ([Weight](https://huggingface.co/lmsys/vicuna-7b-delta-v0)) |
| 4.7 | StackLlama ([Blog](https://huggingface.co/blog/stackllama)), ([Demo](https://huggingface.co/spaces/trl-lib/stack-llama)), ([GitHub](https://github.com/lvwerra/trl/tree/main/examples/stack_llama/scripts)) |
| 4.7 | SegGPT: Segmenting Everything In Context ([arXiv](https://arxiv.org/abs/2304.03284)), ([PDF](https://arxiv.org/pdf/2304.03284.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.03284)), ([GitHub](https://github.com/baaivision/Painter)), ([Demo](https://huggingface.co/spaces/BAAI/SegGPT)) |
| 4.6 | Chrome ships WebGPU ([Blog](https://developer.chrome.com/blog/webgpu-release/)) |
| 4.6 | GPT detectors are biased against non-native English writers ([arXiv](https://arxiv.org/abs/2304.02819)), ([PDF](https://arxiv.org/pdf/2304.02819.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/02819.03411)) |
| 4.6 | ChaosGPT: Empowering GPT with Internet and Memory to Destroy Humanity ([YouTube](https://www.youtube.com/watch?v=g7YJIpkk7KM&t=912s)) |
| 4.6 | InstantBooth: Personalized Text-to-Image Generation without Test-Time Finetuning ([arXiv](https://arxiv.org/abs/2304.03411)), ([PDF](https://arxiv.org/pdf/2304.03411.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.03411)), ([Project](https://jshi31.github.io/InstantBooth/)) | 
| 4.6 | Wired - [AI Desperately Needs Global Oversight](https://www.wired.com/story/ai-desperately-needs-global-oversight/) |
| 4.6 | Instruction Tuning with GPT-4 ([arXiv](https://arxiv.org/abs/2304.03277)), ([PDF](https://arxiv.org/pdf/2304.03277.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.03277)), ([GitHub](https://instruction-tuning-with-gpt-4.github.io/)) |
| 4.6 | GeNVS: Generative Novel View Synthesis with 3D-Aware Diffusion Models ([arXiv](https://arxiv.org/abs/2304.02602)), ([PDF](https://arxiv.org/pdf/2304.02602.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.02602)), ([GitHub](https://nvlabs.github.io/genvs/)) |
| 4.6 | Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark ([arXiv](https://arxiv.org/abs/2304.03279)), ([PDF](https://arxiv.org/pdf/2304.03279.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.03279)) |
| 4.5 | Yoshua Bengio - [Slowing down development of AI systems passing the Turing test](https://yoshuabengio.org/2023/04/05/slowing-down-development-of-ai-systems-passing-the-turing-test/) | 
| 4.5 | Language models are on Replicate - FLAN-T5, GPT-J, and LLaMA ([Blog](https://replicate.com/blog/language-models)) |
| 4.5 | [Meta's  Segment Anything Model (SAM)](https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/?utm_source=twitter&utm_medium=organic_social&utm_campaign=segmentanything&utm_content=gif) ([Paper](https://ai.facebook.com/research/publications/segment-anything/)), ([PDF](https://scontent-ssn1-1.xx.fbcdn.net/v/t39.2365-6/10000000_6331779526880473_6748528980292947838_n.pdf?_nc_cat=102&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=lnYqcLNTtLQAX80UVfV&_nc_ht=scontent-ssn1-1.xx&oh=00_AfAAtzQrBx242Tl4miOfzWrYrJAhLw3VCm1FeWuMs319zw&oe=6432ACEA)), ([GitHub](https://github.com/facebookresearch/segment-anything)), ([Demo](https://segment-anything.com/)), ([arXiv](https://arxiv.org/abs/2304.02643)), ([PDF](https://arxiv.org/pdf/2304.02643.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.02643)) | 
| 4.4 | Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable ([arXiv](https://arxiv.org/abs/2304.01910)), ([PDF](https://arxiv.org/pdf/2304.01910.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.01910)) |
| 4.4 | One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era ([arXiv](https://arxiv.org/abs/2304.06488)), ([PDF](https://arxiv.org/pdf/2304.06488.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06488)) |
| 4.4 | [LangCahin raised $10 million in seed funding](https://blog.langchain.dev/announcing-our-10m-seed-round-led-by-benchmark/) |
| 4.4 | Kandinsky 2.1 ([GitHub](https://github.com/ai-forever/Kandinsky-2)), ([HuggingFace](https://huggingface.co/ai-forever/Kandinsky_2.1)) |
| 4.4 | The weights of Vicuna-13B released ([WebUI demo](https://chat.lmsys.org/)) ([GitHub](https://github.com/lm-sys/FastChat/#vicuna-weights)) |
| 4.4 | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models ([arXiv](https://arxiv.org/abs/2304.01933)), ([PDF](https://arxiv.org/pdf/2304.01933.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.01933)), ([GitHub](https://github.com/AGI-Edgerunners/LLM-Adapters)) |
| 4.4 | Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models ([arXiv](https://arxiv.org/abs/2304.01852)), ([PDF](https://arxiv.org/pdf/2304.01852.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.01852)) |
| 4.3 | Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling ([arXiv](https://arxiv.org/abs/2304.01373)), ([PDF](https://arxiv.org/pdf/2304.01373.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.01373)) |
| 4.3 | Vicuna-13B: An Open-Source ChatGPT Alternative That Impresses GPT-4 ([Blog](https://docs.kanaries.net/articles/vicuna-chatgpt-alternative)), ([GitHub](https://github.com/lm-sys/FastChat)) |
| 4.3 | Baby AGI ([GitHub](https://github.com/yoheinakajima/babyagi)) |
| 4.3 | [Berkley just released Koala-13B!](https://bair.berkeley.edu/blog/2023/04/03/koala/) ([Demo](https://chat.lmsys.org/?model=koala-13b)) |
| 4.3 | [2023 Artificial Intelligence (AI) Index Report](https://aiindex.stanford.edu/report/) Published by Stanford Institute for Human-Centered Artificial Intelligence (HAI) |
| 4.3 | The LLM playground - open source ([Github](https://github.com/nat/openplayground)) |
| 4.3 | Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data ([arXiv](https://arxiv.org/abs/2304.01196)), ([PDF](https://arxiv.org/pdf/2304.01196.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.01196)), ([GitHub](https://github.com/project-baize/baize)) |
| 4.2 | GPTCache : A Library for Creating Semantic Cache for LLM Queries - ([GitHub]()) |
| 4.2 | Better Language Models of Code through Self-Improvement ([arXiv](https://arxiv.org/abs/2304.01228)), ([PDF](https://arxiv.org/pdf/2304.01228.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.01228)) |
| 4.2 | Eight Things to Know about Large Language Models ([arXiv](https://arxiv.org/abs/2304.00612)), ([PDF](https://arxiv.org/pdf/2304.00612.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.00612)) |
| 4.2 | LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models ([arXiv](https://arxiv.org/abs/2304.00457)), ([PDF](https://arxiv.org/pdf/2304.00457.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.00457)) |
| 4.1 | [Italy curbs ChatGPT, starts probe over privacy concerns](https://www.cnbc.com/2023/04/01/italy-curbs-chatgpt-starts-probe-over-privacy-concerns.html) |
| 3.31 | Choose Your Weapon: Survival Strategies for Depressed AI Academics ([arXiv](https://arxiv.org/abs/2304.06035)), ([PDF](https://arxiv.org/pdf/2304.06035.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.06035)) |
| 3.31 | CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society ([arXiv](https://arxiv.org/abs/2303.17760)), ([PDF](https://arxiv.org/pdf/2303.17760.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.17760)), ([GitHub](https://github.com/lightaime/camel)) |
| 3.31 | A Survey of Large Language Models - Version 1 ([arXiv](https://arxiv.org/abs/2303.18223v1)), ([PDF](https://arxiv.org/pdf/2303.18223v1.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.18223v1)) |
| 3.31 | (SCIENTIFIC AMERICAN) [AI Chatbots Can Diagnose Medical Conditions at Home. How Good Are They?](https://www.scientificamerican.com/article/ai-chatbots-can-diagnose-medical-conditions-at-home-how-good-are-they/) |
| 3.30 | ChatGPT in Healthcare: A Taxonomy and Systematic Review ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1.full)), ([PDF](https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1.full.pdf)) |
| 3.30 | Launching the Generative AI Open Source (GenOS) Index - ([Index](https://www.decibel.vc/articles/launching-the-generative-ai-open-source-genos-index)), ([Tweet](https://twitter.com/chakrabartis/status/1641447121042964482)) |
| 3.30 | Whose Opinions Do Language Models Reflect? ([arXiv](https://arxiv.org/abs/2303.17548)), ([PDF](https://arxiv.org/pdf/2303.17548.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.17548)), ([GitHub](https://github.com/tatsu-lab/opinions_qa)) |
| 3.30 | Language Models can Solve Computer Tasks ([arXiv](https://arxiv.org/abs/2303.17491)), ([PDF](https://arxiv.org/pdf/2303.17491.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.17491)) |
| 3.30 | Self-Refine: Iterative Refinement with Self-Feedback ([arXiv](https://arxiv.org/abs/2303.17651)), ([PDF](https://arxiv.org/pdf/2303.17651.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.17651)) |
| 3.30 | Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure ([arXiv](https://arxiv.org/abs/2303.17276)), ([PDF](https://arxiv.org/pdf/2303.17276.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.17276)) |
| 3.30 | [List of Open Sourced Fine-Tuned Large Language Models (LLM)](https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76) |
| 3.30 | [NEJM - Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine](https://www.nejm.org/doi/pdf/10.1056/NEJMsr2214184) |
| 3.30 | BloombergGPT: A Large Language Model for Finance ([arXiv](https://arxiv.org/abs/2303.17564)), ([PDF](https://arxiv.org/pdf/2303.17564.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.17564)) |
| 3.30 | [Got It AI’s ELMAR challenges GPT-4 and LLaMa, scores well on hallucination benchmarks](https://venturebeat.com/ai/got-it-ai-elmar-challenges-gpt-4-and-llama) |
| 3.30 | HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace ([arXiv](https://arxiv.org/abs/2303.17580)), ([PDF](https://arxiv.org/pdf/2303.17580.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.17580)) |
| 3.30 | [CAIDP claims "The FTC should investigate OpenAI and block GPT over ‘deceptive’ behavior"](https://edition.cnn.com/2023/03/30/tech/ftc-openai-gpt-ai-think-tank/index.html) |
| 3.30 | [Epic to use Microsoft's GPT-4 in EHRs](https://www.beckershospitalreview.com/ehrs/epic-to-use-microsofts-open-ai-in-ehrs.html) |
| 3.30 | Auto-GPT: An Autonomous GPT-4 Experiment ([GitHub](https://github.com/Torantulino/Auto-GPT)) |
| 3.29 | AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators ([arXiv](https://arxiv.org/abs/2303.16854)), ([PDF](https://arxiv.org/pdf/2303.16854.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.16854)) |
| 3.29 | [nucleotide transformers - genomics LLM, ranging from 500M to 2.5B parameters](https://twitter.com/instadeepai/status/1641075963051012097) - ([GitHub](https://github.com/instadeepai/nucleotide-transformer)) |
| 3.29 | [GeoV-9b - 9 billion parameter causal language model](https://twitter.com/labmlai/status/1641357802009395201) ([code](https://github.com/geov-ai/geov), [weights](https://huggingface.co/GeoV/GeoV-9b), [colab](https://colab.research.google.com/github/geov-ai/geov/blob/master/notebooks/generate.ipynb)) |
|	3.29	|	[GPT4All - 7B param language model finetuned from a curated set of 400k GPT-Turbo-3.5](https://twitter.com/andriy_mulyar/status/1640836003194630144)  	|
|	3.29	|	[LLaMA-Adapter!: Efficient Fine-tuning of Language Models with Zero-init Attention](https://twitter.com/lupantech/status/1640899600281395200)	|
|	3.29	|	[MacGPT 3.2](https://www.macgpt.com/)	|
| 3.29 | GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment ([arXiv](https://arxiv.org/abs/2303.16634)), ([PDF](https://arxiv.org/pdf/2303.16634.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.16634)) |
| 3.29 | TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs  ([arXiv](https://arxiv.org/abs/2303.16434)), ([PDF](https://arxiv.org/pdf/2303.16434.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.16434)) |
| 3.28 | Natural Selection Favors AIs over Humans [arXiv](https://arxiv.org/abs/2303.16200)), ([PDF](https://arxiv.org/pdf/2303.16200.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.16200)) |
| 3.28 | ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks ([arXiv](https://arxiv.org/abs/2303.15056)), ([PDF](https://arxiv.org/pdf/2303.15056.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.15056)) |
|	3.28	|	[LLaMA voice chat + Siri TTS](https://twitter.com/ggerganov/status/1640416314773700608)	|
|	3.28	|	[Cerebras-GPT - 111M to 13B parameters trained using the Chinchilla formula](https://twitter.com/CerebrasSystems/status/1640725880711569408)	|
|	3.28	|	[Microsoft Security Copilot: Empowering defenders at the speed of AI](https://blogs.microsoft.com/blog/2023/03/28/introducing-microsoft-security-copilot-empowering-defenders-at-the-speed-of-ai/)	|
| 3.28 | [Google pix2struct launched today, a multimodal model specializing in screenshot data](https://twitter.com/danielgross/status/1640515851014004737) |
|	3.28	|	[OpenFlamingo - a framework that enables training and evaluation of large multimodal models (LMMs)](https://laion.ai/blog/open-flamingo/)	|
| 3.27 | Microsoft JARVIS ([GitHub](https://github.com/microsoft/JARVIS)) |
| 3.27 | [ChatGPT Survey: Performance on NLP datasets](http://opensamizdat.com/posts/chatgpt_survey/) |
| 3.27 | GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models ([arXiv](https://arxiv.org/abs/2303.10130)), ([PDF](https://arxiv.org/pdf/2303.10130.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.10130)) |
| 3.26 | Nature Language Reasoning, A Survey ([arXiv](https://arxiv.org/abs/2303.14725)), ([PDF](https://arxiv.org/pdf/2303.14725.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.14725)) |
|	3.26	|	[Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI - Lex Fridman Podcast #367](https://www.youtube.com/watch?v=L_Guz73e6fw)	|
|	3.26	|	[LLaMA voice chat](https://twitter.com/ggerganov/status/1640022482307502085)	|
|	3.26	|	[Japanese Alpaca LoRA](https://twitter.com/kun1em0n/status/1639965140429963264)	|
| 3.24 | Efficient Methods for Natural Language Processing: A Survey ([arXiv](https://arxiv.org/abs/2209.00099)),  ([PDF](https://arxiv.org/pdf/2209.00099.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2209.00099)) |
|	3.24	|	[NYT OPINION - You Can Have the Blue Pill or the Red Pill, and We’re Out of Blue Pills](https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html)	([archive](https://archive.is/AUKPm)) |
|	3.24	|	[Dolly - open source LLM](https://twitter.com/databricks/status/1639239800145465344) 	|
|	3.24	|	[Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators](https://twitter.com/_akhaliq/status/1639062868850266112)	|
|	3.24	|	ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge ([arXiv](https://arxiv.org/abs/2303.14070v1)),  ([PDF](https://arxiv.org/pdf/2303.14070v1.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.14070v1)), ([GitHub](https://github.com/Kent0n-Li/ChatDoctor))	|
| 3.24 | Do large language models need sensory grounding for meaning and understanding? @YannLeCun |
|	3.23	|	[OpenAI: ChatGPT Plugins](https://openai.com/blog/chatgpt-plugins)	|
|	3.23	|	[Opera brings AI ChatGPT bot sidebar to browsers](https://www.deccanherald.com/business/technology/opera-brings-ai-chatgpt-bot-sidebar-to-browsers-1202781.html)	|
| 3.22 | Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity ([arXiv](https://arxiv.org/abs/2303.12003)), ([PDF](https://arxiv.org/pdf/2303.12003.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.12003)) |	
|	3.22	|	[GitHub: Copilot X](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience)	|
|	3.22	|	Sparks of AGI(Artificial General Intelligence): Early experiments with GPT-4 ([arXiv](https://arxiv.org/abs/2303.12712)), ([PDF](https://arxiv.org/pdf/2303.12712.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.12712)), ([YouTube](https://www.youtube.com/watch?v=qbIk7-JPB2c)) |
|	3.22	|	[Pause Giant AI Experiments: An Open Letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/)	|
| 3.21 | WSJ - [Generative AI Makes Headway in Healthcare](https://www.wsj.com/articles/generative-ai-makes-headway-in-healthcare-cb5d4ee2) |
|	3.21	|	[NVIDIA Brings Generative AI to World’s Enterprises](https://nvidianews.nvidia.com/news/nvidia-brings-generative-ai-to-worlds-enterprises-with-cloud-services-for-creating-large-language-and-visual-models)	|
|	3.21	|	[Adobe launches Firefly](https://www.cnbc.com/2023/03/21/adobe-firefly-generative-ai-lets-you-type-to-edit-images.html)	|
|	3.21	|	[Google launches Bard in the US and UK](https://blog.google/technology/ai/try-bard)	|
|	3.21	|	[Microsoft: Bing Image Creator](https://blogs.microsoft.com/blog/2023/03/21/create-images-with-your-words-bing-image-creator-comes-to-the-new-bing)	|
|	3.21	|	[Stability AI Launches Stable Diffusion Reimagine](https://stability.ai/blog/stable-diffusion-reimagine)	|
| 3.20 | Reflexion: an autonomous agent with dynamic memory and self-reflection ([arXiv](https://arxiv.org/abs/2303.11366)), ([PDF](https://arxiv.org/pdf/2303.11366.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.11366)), ([GitHub](https://github.com/noahshinn024/reflexion)) |
|	3.20	|	[March 20 ChatGPT outage: Here’s what happened](https://openai.com/blog/march-20-chatgpt-outage)	|
|	3.20	|	[Runway Gen-2](https://research.runwayml.com/gen2)	|
|	3.20	|	[Paper: Capabilities of GPT-4 on Medical Challenge Problems](https://arxiv.org/abs/2303.13375)	|
| 3.20 | [Making Music with GPT 4](https://www.youtube.com/watch?v=Cvl30rn03Hg) by [(Wavtool)](https://wavtool.com/) |
| 3.19 | Simple LLM Finetuner ([GitHub](https://github.com/lxe/simple-llm-finetuner)) |
| 3.18 | Data-centric Artificial Intelligence: A Survey ([arXiv](https://arxiv.org/abs/2303.10158)), ([PDF](https://arxiv.org/pdf/2303.10158.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.10158)), ([GitHub](https://github.com/daochenzha/data-centric-AI)) |
| 3.17 | Can AI-Generated Text be Reliably Detected? ([arXiv](https://arxiv.org/abs/2303.11156)), ([PDF](https://arxiv.org/pdf/2303.11156.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.11156)) |
| 3.17 | GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models  ([arXiv](https://arxiv.org/abs/2303.10130)), ([PDF](https://arxiv.org/pdf/2303.10130.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.10130)) |
| 3.16 | WebSHAP: Towards Explaining Any Machine Learning Models Anywhere ([arXiv](https://arxiv.org/abs/2303.09545)), ([PDF](https://arxiv.org/pdf/2303.09545.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.09545)), ([GitHub](https://poloclub.github.io/webshap/)) |
| 3.16 | LERF: Language Embedded Radiance Fields ([arXiv](https://arxiv.org/abs/2303.09553)), ([PDF](https://arxiv.org/pdf/2303.09553.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.09553)), ([GitHub](https://www.lerf.io/)) |
|	3.16	|	[Microsoft: Microsoft 365 Copilot](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work)	|
|	3.16	|	[Alpaca LoRA: instruct tune LLAMA on consumer hardware](https://twitter.com/_akhaliq/status/1636416647518097408)	|
|	3.16	|	[OpenAI CEO Sam Altman says AI will reshape society, acknowledges risks: 'A little bit scared of this'](https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122)	|
|	3.15	|	[A new era for AI and Google Workspace](https://workspace.google.com/blog/product-announcements/generative-ai?hl=en)	|
|	3.15	|	[PyTorch 2.0: Our next generation release](https://pytorch.org/blog/pytorch-2.0-release/)	|
|	3.15	|	[Baidu: ERNIE Bot](https://www.youtube.com/watch?v=ukvEUI3x0vI)	|
|	3.15	|	[Midjourney: Midjourney V5](https://twitter.com/midjourney/status/1636130389365497857)	|
|	3.15	|	[arXiv - GPT-4 Technical report](https://arxiv.org/abs/2303.08774)	|
| 3.14 | The Lancet - [Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine](https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00077-4/fulltext) |
|	3.14	|	THUDM releases ChatGLM-6B	|
|	3.14	|	[Anthropic: Claude](https://www.anthropic.com/index/introducing-claude)	|
|	3.14	|	[Google: PaLM API & Workspace](https://blog.google/technology/ai/ai-developers-google-cloud-workspace)	|
|	3.14	|	[OpenAI: GPT-4](https://openai.com/research/gpt-4)	|
|	3.13	|	[Stanford Alpaca 7B](https://crfm.stanford.edu/2023/03/13/alpaca.html)	|
|	3.13	|	[Microsoft lays off team that taught employees how to make AI tools responsibly](https://www.theverge.com/2023/3/13/23638823/microsoft-ethics-society-team-responsible-ai-layoffs)	|
|	3.13	|	[MiniLLM: Large Language Models on Consumer GPUs](https://github.com/kuleshov/minillm)	|
| 3.13 | Chatbot UI ([Github](https://github.com/mckaywrigley/chatbot-ui)) |
|	3.12	|	[GM explores using ChatGPT in vehicles](https://europe.autonews.com/automakers/gm-explores-using-chatgpt-vehicles)	|
|	3.10	|	[Google: PaLM-E](https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html)	|
|	3.9	|	[multi-model playground - https://nat.dev](https://nat.dev/)	|
|	3.9	|	[GPT-4 is coming next week](https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html)	|
| 3.8 | Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models ([arXiv](https://arxiv.org/abs/2303.04671)), ([PDF](https://arxiv.org/pdf/2303.04671.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.04671)) |
|	3.8	|	[NYT, Opinion - Noam Chomsky: The False Promise of ChatGPT](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html)	([archive](https://archive.is/qvR3Q))|
| 3.7 | A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT ([arXiv](https://arxiv.org/abs/2303.04226)), ([PDF](https://arxiv.org/pdf/2303.04226.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.04226)) |
| 3.7 | Radiology - [The Role and Limitations of Large Language Models Such as ChatGPT in Clinical Settings and Medical Journalism](https://pubs.rsna.org/doi/10.1148/radiol.230276) |
|	3.7	|	[Stability AI Acquires Image Editing App Clipdrop](https://stability.ai/blog/stability-ai-acquires-init-ml-makers-of-clipdrop-application)	|
|	3.6	|	[Google: Universal Speech Model](https://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html)	|
|	3.5	|	[Generative AI: Perspectives from Stanford HAI](https://hai.stanford.edu/generative-ai-perspectives-stanford-hai)	|
|	3.5	|	[UpStage, ChatGPT bot (Askup) on Line](https://github.com/hunkim/line-gpt)	|
|	3.5	|	[UpStage, ChatGPT bot (Askup) on KakaoTalk](https://github.com/hunkim/kakao-gpt)	|
| 3.2 | Consistency Models  ([arXiv](https://arxiv.org/abs/2303.01469)), ([PDF](https://arxiv.org/pdf/2303.01469.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2303.01469)), ([GitHub](https://github.com/openai/consistency_models)) |
|	3.1	|	[OpenAI: ChatGPT and Whisper API](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)	|
| 2.28 | Large Language Models Are State-of-the-Art Evaluators of Translation Quality ([arXiv](https://arxiv.org/abs/2302.14520)), ([PDF](https://arxiv.org/pdf/2302.14520.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2302.14520)) |
| 2.27 | Best Practices for Using AI When Writing Scientific Manuscripts ([ACS Nano 2023, 17, 5, 4091–4093](https://doi.org/10.1021/acsnano.3c01544)) |
|	2.27	|	[Fighting ‘Woke AI,’ Musk Recruits Team to Develop OpenAI Rival](https://www.theinformation.com/articles/fighting-woke-ai-musk-recruits-team-to-develop-openai-rival)	|
| 2.25 | The Lancet - [The promise of large language models in health care](https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(23)00216-7/fulltext) |
| 2.25 | AugGPT: Leveraging ChatGPT for Text Data Augmentation ([arXiv](https://arxiv.org/abs/2302.13007)), ([PDF](https://arxiv.org/pdf/2302.13007.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2302.13007)) |
|	2.24	|	[Sam Altman, Planning for AGI and beyond](https://openai.com/blog/planning-for-agi-and-beyond)	|
|	2.24	|	[Meta: LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai)	|
| 2.23 | Radiology - [ChatGPT and the Future of Medical Writing](https://pubs.rsna.org/doi/10.1148/radiol.223312) |
|	2.23	|	[Instagram co-founders launch AI-powered news app Artifact on Android, iOS](https://www.thehindubusinessline.com/info-tech/social-media/instagram-co-founders-launch-ai-powered-news-app-artifact-on-android-ios/article66543779.ece)	|
|	2.23	|	[Notion.AI launch](http://notion.ai/)	|
| 2.22 | The alignment problem from a deep learning perspective ([arXiv](https://arxiv.org/abs/2209.00626)), ([PDF](https://arxiv.org/pdf/2209.00626.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2209.00626))	|
|	2.22	|	[Microsoft: Bing announcement on mobile and Skype](https://blogs.microsoft.com/blog/2023/02/22/the-new-bing-preview-experience-arrives-on-bing-and-edge-mobile-apps-introducing-bing-now-in-skype)	|
|	2.22	|	Science - [As scientists explore AI-written text, journals hammer out policies](https://www.science.org/content/article/scientists-explore-ai-written-text-journals-hammer-policies)	|
| 2.21 | BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT ([arXiv](https://arxiv.org/abs/2304.12298)), ([PDF](https://arxiv.org/pdf/2304.12298.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2304.12298))	|
| 2.21 | Hyena Hierarchy: Towards Larger Convolutional Language Models ([arXiv](https://arxiv.org/abs/2302.10866)), ([PDF](https://arxiv.org/pdf/2302.10866.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2302.10866))	|
|	2.21	|	[The PNAS Journals Outline Their Policies for ChatGPT and Generative AI](https://www.pnas.org/post/update/pnas-policy-for-chatgpt-generative-ai)	|
|	2.21	|	ChatGPT: Jack of all trades, master of none ([arXiv](https://arxiv.org/abs/2302.10724)), ([PDF](https://arxiv.org/pdf/2302.10724.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2302.10724))	|
|	2.17	|	[Time, ChatGPT cover](https://time.com/6255952/ai-impact-chatgpt-microsoft-google/)	|
|	2.17	|	OpenAI, Foundry Product Brief	|
|	2.17	|	[Generative AI on Roblox: Our Vision for the Future of Creation](https://blog.roblox.com/2023/02/generative-ai-roblox-vision-future-creation/)	|
| 2.16 | Do We Still Need Clinical Language Models? ([arXiv](https://arxiv.org/abs/2302.08091)), ([PDF](https://arxiv.org/pdf/2302.08091.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2302.08091)) |
|	2.16	|	[Startup Replit launches a ChatGPT-like bot for coders](https://www.semafor.com/article/02/15/2023/startup-replit-launches-a-chatgpt-like-bot-for-coders)	|
|	2.15	|	[A&O announces exclusive launch partnership with Harvey](https://www.allenovery.com/en-gb/global/news-and-insights/news/ao-announces-exclusive-launch-partnership-with-harvey)	|
|	2.14	|	1M ChatGPT plus user 	|
|	2.14	|	[The Gen AI Conference Hosted by Jasper](https://www.joingen.ai/)	|
|	2.13	|	[Google: Vision Transformer 22B](https://twitter.com/m__dehghani/status/1625186144001396737)	|
| 2.12 | Transformer models: an introduction and catalog ([arXiv](https://arxiv.org/abs/2302.07730)), ([PDF](https://arxiv.org/pdf/2302.07730.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2302.07730)), ([Blog](https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/)) |
|	2.10	|	[arXivGPT launches](https://news.ycombinator.com/item?id=34770108)	|
|	2.10	|	[OpenAI, ChatGPT plus announce (20$)](https://openai.com/blog/chatgpt-plus)	|
|	2.9	|	[Disastrous Chatbot Demo Costs Google $140 Billion](https://www.channelnews.com.au/google-shares-tank-after-disastrous-chatbot-demo/)	|
|	2.9	|	[Meta: Toolformer](https://arxiv.org/abs/2302.04761)	|
| 2.8 | A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity ([arXiv](https://arxiv.org/abs/2302.04023)), ([PDF](https://arxiv.org/pdf/2302.04023.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2302.04023)) | 
|	2.8	|	[Runway launches ground-breaking Gen-1 video generation AI system](https://www.ghacks.net/2023/02/08/runway-launches-ground-breaking-gen-1-video-generation-ai-system/)	|
|	2.7	|	[Microsoft: Bing ChatGPT](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/)	|
|	2.7	|	[Getty Images sues AI art generator Stable Diffusion in the US for copyright infringement](https://www.theverge.com/2023/2/6/23587393/ai-art-copyright-lawsuit-getty-images-stable-diffusion)	|
| 2.6 | The Lancet - [ChatGPT: friend or foe?](https://www.thelancet.com/journals/landig/article/PIIS2589-7500%2823%2900023-7/fulltext) |
|	2.6	|	[Google: Bard announcement](https://blog.google/technology/ai/bard-google-ai-search-updates)	|
| 2.4 | Theory of Mind May Have Spontaneously Emerged in Large Language Models  ([arXiv](https://arxiv.org/abs/2302.02083)), ([PDF](https://arxiv.org/pdf/2302.02083.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2302.02083)) |
|	2.4	|	[POE.com open](http://poe.com/)	|
|	2.3	|	[Google invests in Anthropic, maker of ChatGPT rival](https://fortune.com/2023/02/04/google-invests-300m-anthropic-openai-rival-making-chatgpt-challenger-claude-ai-chatbot-battle/) 	|
|	2.3	|	Naver, SearchGPT announcement	|
| 2.2 | Creating a Large Language Model of a Philosopher ([arXiv](https://arxiv.org/abs/2302.01339)), ([PDF](https://arxiv.org/pdf/2302.01339.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2302.01339)) |
|	2.2	|	[ChatGPT reaches 100 million users two months after launch](https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app)	|
| 2.1 | The Diagnostic and Triage Accuracy of the GPT-3 Artificial Intelligence Model ([medrXiv](https://www.medrxiv.org/content/10.1101/2023.01.30.23285067v1 )|
|	2.1	|	[OpenAI, released a software tool to help identify text generated by AI](https://eandt.theiet.org/content/articles/2023/02/chatgpt-owner-launches-imperfect-tool-to-detect-ai-generated-text/)	|
|	1.31	|	[JAMA Network - Nonhuman “Authors” and Implications for the Integrity of Scientific Publication and Medical Knowledge](https://jamanetwork.com/journals/jama/fullarticle/2801170)	|
| 1.30 | SingSong: Generating musical accompaniments from singing ([arXiv](https://arxiv.org/abs/2301.12662)), ([PDF](https://arxiv.org/pdf/2301.12662.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2301.12662)), ([GitHub](https://storage.googleapis.com/sing-song/index.html)) |
|	1.30	|	[China's biggest search engine is to set launch a ChatGPT rival in March](https://www.engadget.com/chinas-baidu-is-adding-a-chatgpt-type-bot-to-its-search-engine-110452638.html)	|
|	1.26	|	[Science Journal - ChatGPT is fun, but not an author](https://www.science.org/doi/10.1126/science.adg7879)	|
|	1.26	|	DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature ([arXiv](https://arxiv.org/abs/2301.11305)), ([PDF](https://arxiv.org/pdf/2301.11305.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2301.11305))	|
|	1.26	|	[ChatGPT Is Coming for Classrooms. Don't Panic](https://www.wired.com/story/chatgpt-is-coming-for-classrooms-dont-panic/)	|
|	1.26	|	[ChatGPT passes exams from law and business schools](https://edition.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html)	|
|	1.26	|	[Google’s new AI turns text into music - MusicLM](https://google-research.github.io/seanet/musiclm/examples/)	|
| 1.24 | Putting ChatGPT's Medical Advice to the (Turing) Test ([arXiv](https://arxiv.org/abs/2301.10035)), ([PDF](https://arxiv.org/pdf/2301.10035.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2301.10035)) |
|	1.24	|	[Nature policy - Tools such as ChatGPT threaten transparent science; here are our ground rules for their use](https://www.nature.com/articles/d41586-023-00191-1)	|
|	1.20	|	[WAME policy - Chatbots, ChatGPT, and Scholarly Manuscripts](https://wame.org/page3.php?id=106)	|
|	1.17	|	[Meet Claude: Anthropic’s Rival to ChatGPT](https://scale.com/blog/chatgpt-vs-claude)	|
|	1.14	|	[Microsoft in talks to acquire a 49% stake in ChatGPT owner OpenAI](https://watcher.guru/news/microsoft-plans-to-acquire-a-49-stake-in-chatgpt-owner-openai)	|
| 1.12 | Multimodal Deep Learning ([arXiv](https://arxiv.org/abs/2301.04856)), ([PDF](https://arxiv.org/pdf/2301.04856.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2301.04856)) |
|	1.11	|	[This Voice Doesn't Exist - Generative Voice AI](https://blog.elevenlabs.io/enter-the-new-year-with-a-bang/)	|
|	1.9	|	[Microsoft is looking at OpenAI’s GPT for Word, Outlook, and PowerPoint](https://www.theverge.com/2023/1/9/23546144/microsoft-openai-word-powerpoint-outlook-gpt-integration-rumor)	|
|	1.5	|	[Apple launches AI-powered book narrations](https://techcrunch.com/2023/01/05/apple-launches-ai-powered-book-narrations/)	|
|	1.5	|	[Microsoft, VALL-E](https://valle-demo.github.io/)	|
|	1.4	|	[ICML conference responds to LLM ethics rule](https://venturebeat.com/ai/thats-so-meta-ml-conference-debates-use-of-chatgpt-in-papers/)	|
|	1.3	|	[Enter GPTZeo](https://twitter.com/edward_the6/status/1610067688449007618?ref_src=twsrc%5Etfw)	|
|	2023.01.01	|	Collected by Jonghong Jeon (hollobit@etri.re.kr)	|
|	12.29	|	GPT Takes the Bar Exam ([arXiv](https://arxiv.org/abs/2212.14402)), ([PDF](https://arxiv.org/pdf/2212.14402.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2212.14402))	|
|	12.27	|	[bioarXiv - Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers](https://www.biorxiv.org/content/10.1101/2022.12.23.521610v1)	|
|	11.30	|	[OpenAI, ChatGPT service](https://openai.com/blog/chatgpt)	|
|	11.28	|	[NeurIPS 2022 conference](https://nips.cc/Conferences/2022)	|
|	11.17	|	[InstructPix2Pix: Learning to Follow Image Editing Instructions](https://arxiv.org/abs/2211.09800)	|
| 11.16 | Holistic Evaluation of Language Models ([arXiv](https://arxiv.org/abs/2211.09110)), ([PDF](https://arxiv.org/pdf/2211.09110.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2211.09110))	|
|	10.30	|	[LlamaIndex (GPT Index) GitHub project](https://github.com/jerryjliu/llama_index)	|
|	10.23	|	[LangChain GitHub project](https://github.com/hwchase17/langchain)	|
|	9.19	|	[SEQUOIA - Generative AI: A Creative New World](https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/)	|
| 8.25 | Understanding Diffusion Models: A Unified Perspective ([arXiv](https://arxiv.org/abs/2208.11970)), ([PDF](https://arxiv.org/pdf/2208.11970.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2208.11970)), ([Blog](https://calvinyluo.com/2022/08/26/diffusion-tutorial.html)) |
|	3.15	|	OpenAI, GPT 3.5 announce	|
| 2.11 | Compute Trends Across Three Eras of Machine Learning ([arXiv](https://arxiv.org/abs/2202.05924)), ([PDF](https://arxiv.org/pdf/2202.05924.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2202.05924)) |
| 2022.01.01 | |
| 8.16 | On the Opportunities and Risks of Foundation Models ([arXiv](https://arxiv.org/abs/2108.07258)), ([PDF](https://arxiv.org/pdf/2108.07258.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2108.07258)) |
| 4.18 | The Power of Scale for Parameter-Efficient Prompt Tuning ([arXiv](https://arxiv.org/abs/2104.08691)), ([PDF](https://arxiv.org/pdf/2104.08691.pdf)), ([arXiv-vanity](https://www.arxiv-vanity.com/papers/2104.08691))
| 2021.01.01 | | 
|		|	**Last Modified 2023/04/14 PM19:40** KST	|

## Additional Links
* [AI Incident Database](https://incidentdatabase.ai/)
* [Daily papers by AK](https://huggingface.co/papers)
* [Awesome-Generative-RecSys](https://github.com/jihoo-kim/Awesome-Generative-RecSys) - A curated list of Generative Recommender Systems (Paper & Code)
* [Prompt Engineering Guide](https://www.promptingguide.ai/) - [papers](https://www.promptingguide.ai/papers) - [Github](https://github.com/dair-ai/Prompt-Engineering-Guide)
* [awesome-ChatGPT-repositories](https://github.com/taishi-i/awesome-ChatGPT-repositories) 
* [The Rundown](https://www.therundown.ai/)
* [WEEKLY PAPERS](https://papers.labml.ai/papers/weekly)
* [Primo.ai LLM wiki](https://primo.ai/index.php?title=Large_Language_Model_(LLM))
* [ML Papers of the Week](https://github.com/dair-ai/ML-Papers-of-the-Week)
* [CS 324 - Advances in Foundation Models](https://stanford-cs324.github.io/winter2023/)
* [ML timeline](https://github.com/osanseviero/ml_timeline)
* [ChatGPT Timeline](https://timelines.issarice.com/wiki/Timeline_of_ChatGPT)
* [OpenAI Timeline](https://www.jointjs.com/demos/chatgpt-timeline)
* [The Practical Guides for Large Language Models](https://github.com/Mooler0410/LLMsPracticalGuide)
<img src="https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/survey-gif-test.gif">
* [AI / ML / LLM / Transformer Models Timeline](https://ai.v-gar.de/ml/transformer/timeline/) 
<img src="https://ai.v-gar.de/ml/transformer/timeline/timeline.png">
* [Transformer models: an introduction and catalog — 2023 Edition](https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/)
<img src="https://amatriain.net/blog/images/02-05.png" bgcolor=white>
<img src="https://amatriain.net/blog/images/02-09.png">
* [open-source LLMs](https://twitter.com/theaievangelist/status/1645809824314298368)
<img src="https://pbs.twimg.com/media/FtZQSU3aMAI4BP1?format=jpg&name=4096x4096">
* Got It AI’s LLM hallucination rate comparison
<img src="https://lh5.googleusercontent.com/cgHE-XSe8AZBUuFIQw-Vu6XqYFxvKWj5BjCPsWAxkre2G8WLLkVLhp0DyDTlSTYFQiUyG_XUvZU2ZtM212SuU9rfbNxEtQI0kEpm8sSKF7CUsJZpu0pY9FaT2qHVpPgrBRLeJZdsdyBaKMw5Tac8M7Y">
* [A summary of large language models @davidtfoster](https://media.licdn.com/dms/image/D4E22AQEoWortzcTOKA/feedshare-shrink_800/0/1679661353407?e=1683158400&v=beta&t=RuQk8zpi_PYX58stAajuZBXmJP3JW36yu8n6UjSM09U)
 <img src="https://media.licdn.com/dms/image/D4E22AQEoWortzcTOKA/feedshare-shrink_1280/0/1679661353407?e=1683158400&v=beta&t=yDdqi4f6vX6Tpx5h3NMO6lCYwUMHnOLG-PbZEcBvdFY">
* [A history of the most important generative AI models, from 2014 to 2023 @davidtfoster](https://www.linkedin.com/feed/update/urn:li:activity:7044233450295316480/)
 <img src="https://media.licdn.com/dms/image/C4E22AQHNRDAc2ujyzA/feedshare-shrink_1280/0/1679476129468?e=1683158400&v=beta&t=PC1QOR-aloKbP7w1QXrFUswJmTLXsl7K8dj_fZVvD_Y">
